
<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0" />
    <meta name="google-site-verification" content="VXixwtxrf--qUV1swfStEg9jOGPKgUm6C3Ub_vouqmc" />
    <title>MecBar | The Mec Evolution </title>
    <link rel="icon" href="foto/favicon.ico"/>
    <!-- CSS  -->
    <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection" />
    
    <script src="js/jquery-3.js"></script>
    
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
   
    <link href="https://fonts.googleapis.com/css?family=Raleway|Satisfy" rel="stylesheet">
    <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection" />

    <link href="css/style2.css" type="text/css" rel="stylesheet" media="screen,projection" />
    <link href="css/navbar.css" type="text/css" rel="stylesheet" media="screen,projection" />
 
</head>
<body>
<header>
    <nav>
        <li class="nav-wrapper back-home" id="head">
            <a href="http://www.mecbar.com/" class="brand-logo mecbar">
                <?xml version="1.0" encoding="UTF-8" standalone="no"?>
                <svg
                   xmlns:osb="http://www.openswatchbook.org/uri/2009/osb"
                   xmlns:dc="http://purl.org/dc/elements/1.1/"
                   xmlns:cc="http://creativecommons.org/ns#"
                   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                   xmlns:svg="http://www.w3.org/2000/svg"
                   xmlns="http://www.w3.org/2000/svg"
                   xmlns:xlink="http://www.w3.org/1999/xlink"
                   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
                   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
                   width="156"
                   height="64"
                   viewBox="0 0 12.3825 5.08"
                   version="1.1"
                   id="svg8"
                   inkscape:version="1.0 (6e3e5246a0, 2020-05-07)"
                   sodipodi:docname="mecbar.svg">
                  <defs
                     id="defs2">
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient2948">
                      <stop
                         id="stop2946"
                         offset="0"
                         style="stop-color:#c6126a;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient875">
                      <stop
                         id="stop873"
                         offset="0"
                         style="stop-color:#babd06;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3253"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#878734;stop-opacity:1;"
                         offset="0"
                         id="stop3251" />
                    </linearGradient>
                    <linearGradient
                       inkscape:collect="always"
                       id="linearGradient3093">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3089" />
                      <stop
                         style="stop-color:#c6126a;stop-opacity:0;"
                         offset="1"
                         id="stop3091" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3071"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3069" />
                    </linearGradient>
                    <rect
                       x="38.182308"
                       y="80.104469"
                       width="51.135052"
                       height="30.274338"
                       id="rect18630" />
                    <rect
                       x="160.31746"
                       y="77.487633"
                       width="134.35785"
                       height="60.829021"
                       id="rect18624" />
                    <rect
                       x="70.354279"
                       y="28.223705"
                       width="103.27115"
                       height="64.638908"
                       id="rect18618" />
                    <rect
                       x="32.55666"
                       y="25.199898"
                       width="5.2916665"
                       height="43.089287"
                       id="rect18612" />
                    <rect
                       x="34.029621"
                       y="65.792862"
                       width="93.441322"
                       height="26.673161"
                       id="rect18606" />
                    <rect
                       x="10.284417"
                       y="19.486744"
                       width="193.27823"
                       height="129.88597"
                       id="rect18596" />
                    <linearGradient
                       inkscape:collect="always"
                       xlink:href="#linearGradient3093"
                       id="linearGradient3101"
                       gradientUnits="userSpaceOnUse"
                       x1="3.1346149"
                       y1="23.792595"
                       x2="78.606865"
                       y2="23.792595" />
                    <filter
                       height="1"
                       y="-2.5183475e-16"
                       width="1"
                       x="-7.1910066e-17"
                       style="color-interpolation-filters:sRGB"
                       inkscape:label="Blend"
                       id="filter3198">
                      <feBlend
                         in2="SourceGraphic"
                         mode="multiply"
                         result="fbSourceGraphic"
                         id="feBlend3196" />
                      <feColorMatrix
                         result="fbSourceGraphicAlpha"
                         in="fbSourceGraphic"
                         values="0 0 0 -1 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0 1 0"
                         id="feColorMatrix3200" />
                      <feBlend
                         in2="fbSourceGraphic"
                         id="feBlend3202"
                         mode="multiply"
                         result="blend"
                         in="fbSourceGraphic" />
                      <feGaussianBlur
                         id="feGaussianBlur869"
                         stdDeviation="6.7542215e-15" />
                    </filter>
                    <linearGradient
                       gradientUnits="userSpaceOnUse"
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       id="linearGradient2950"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                    <linearGradient
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       gradientTransform="translate(2.3455617,-9.683066)"
                       gradientUnits="userSpaceOnUse"
                       id="linearGradient3064"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                  </defs>
                  <sodipodi:namedview
                     id="base"
                     pagecolor="#ffffff"
                     bordercolor="#666666"
                     borderopacity="1.0"
                     inkscape:pageopacity="0.0"
                     inkscape:pageshadow="2"
                     inkscape:zoom="0.7"
                     inkscape:cx="355.19772"
                     inkscape:cy="45.714286"
                     inkscape:document-units="mm"
                     inkscape:current-layer="layer1-6"
                     inkscape:document-rotation="0"
                     showgrid="false"
                     inkscape:window-width="1324"
                     inkscape:window-height="747"
                     inkscape:window-x="36"
                     inkscape:window-y="21"
                     inkscape:window-maximized="1"
                     units="px"
                     inkscape:snap-nodes="true"
                     inkscape:object-paths="true"
                     scale-x="0.3" />
                  <metadata
                     id="metadata5">
                    <rdf:RDF>
                      <cc:Work
                         rdf:about="">
                        <dc:format>image/svg+xml</dc:format>
                        <dc:type
                           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
                        <dc:title></dc:title>
                      </cc:Work>
                    </rdf:RDF>
                  </metadata>
                  <g
                     inkscape:label="Layer 1"
                     inkscape:groupmode="layer"
                     class="io"
                     id="layer1">
                    <rect
                       ry="7.1295023"
                       rx="10.726023"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="21.245117"
                       width="20.103241"
                       id="rect2824"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                    <g
                       inkscape:label="Layer 1"
                       id="layer1-6"
                       transform="matrix(0.16152221,0.0020121,0,0.13626925,0.08059628,0.86541284)"
                       style="mix-blend-mode:normal;fill:url(#linearGradient2950);fill-opacity:1;stroke-width:6.74038;filter:url(#filter3198);image-rendering:optimizeQuality">
                      <text
                         xml:space="preserve"
                         id="text18594"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18596);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;line-height:125%;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;letter-spacing:0px;word-spacing:0px;fill:url(#linearGradient3064);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
                         x="-4.0898471"
                         y="24.876211"
                         id="text18602"
                         transform="matrix(0.75566848,-0.20637119,0.34609071,1.2288151,0,0)"><tspan
                   sodipodi:role="line"
                   id="tspan18600"
                   x="-4.0898471"
                   y="24.876211"
                   style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:url(#linearGradient3064);fill-opacity:1;stroke-width:1.78339px">MecBar</tspan>        <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="0s;light_2.end"
                   dur="1s"
                   values="1;0"
                   attributeName="fill-opacity"
                   id="light_1" />       <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="light_1.end"
                   dur="1s"
                   values="0;1"
                   attributeName="fill-opacity"
                   id="light_2" />           </text>
                      <text
                         xml:space="preserve"
                         id="text18604"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18606);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18610"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18612);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18616"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18618);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18622"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18624);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18628"
                         style="font-style:normal;font-weight:normal;font-size:12.7px;line-height:125%;font-family:sans-serif;text-align:justify;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18630);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="0s;light_2.end"
                         dur="1s"
                         values="1;0"
                         attributeName="fill-opacity"
                         id="light_1" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="light_1.end"
                         dur="1s"
                         values="0;1"
                         attributeName="fill-opacity"
                         id="light_2" />
                    </g>
                    <rect
                       ry="7.1295042"
                       rx="10.726021"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="16.413473"
                       width="25.987757"
                       id="rect871"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                  </g>
                  <style
                     id="style43">
                           #tspan18600 {
                               
                              animation-name: mecOpacity;
                              animation-duration: 2s;
                              animation-iteration-count: infinite;
                              }
                              @keyframes mecOpacity {
                              0%   { fill-opacity:1 }
                                50%  {fill-opacity :0.1; }
                            100% { fill-opacity: 1; }
                              }
                    </style>
                </svg>
                </a>
            <a href="#" data-activates="mobile-demo" class="button-collapse"><i class="material-icons">menu</i></a>

            <ul class="right hide-on-med-and-down">
                <!--  <li> <a class="btn" onclick="Materialize.toast('Hello', 4000, 'Ciao' ,4000 )">Touch Me</a> </li>
              -->

              <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
              <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
                <li>
                    <a href=""> </a>
                </li>
                <li>
                    <a href=""> </a>
                </li>
            </ul>
          
              <ul class="side-nav" id="mobile-demo">
               <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
                 <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
            </ul>
        
            </li>
    </nav>
</header>
<script>
    MathJax = {
      loader: {load: ['input/asciimath', 'output/chtml']}
    }
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<body>
<div class="center titolo">
    <i>PyTorch Neural Network</i>
 </div>

<div class="testo">
PyTorch è un framework che ci permette di utilizza i tensor e dei moduli per creare dei 
modelli di Neural Network. <br><br>

   <span class="titolo2">
      <b>
Tensor in PyTorch </b></span>
<br>
<br>
%matplotlib inline<br>
from __future__ import print_function<br>
 import torch<br>
 import numpy as np<br>
 <br>
 <span class="verde">
y = torch.rand(3,5)<br>
x = torch.empty(3,5)</span>
<br>
print(x.size())<br>
result = torch.empty(3, 5)<br>
<span class="verde">
torch.add(x, y, out=result)<br>
</span>
print(result)<br>
torch.Size([3, 5])<br>
tensor([[8.0163e-01, 5.6948e-01, 7.2250e+28, 7.3528e-01, 9.2911e-01],<br>
        [7.5878e+31, 3.0600e+32, 5.0840e+31, 6.4600e+19, 4.4721e+21],<br>
        [7.2070e+22, 4.7428e+30, 7.8670e-02, 6.4610e+19, 4.6184e-01]])<br>
        <br>
        <span class="titolo2">
         <b>Da numpy a tensor e viceversa </b></span>
            <br>
        <br>
        a = np.zeros(5)<br>
        <span class="pyc2">
        b = torch.from_numpy(a)</span> <br>
        #collegamento tra array originale e tensor utilizzando parametri sottostanti<br>
        np.add(a, 5, out=a)<br>
        print(a)<br>
        print(b)<br>
        <br>
        [5. 5. 5. 5. 5.]<br>
        tensor([5., 5., 5., 5., 5.], dtype=torch.float64)<br>
        <br>
        <span class="titolo2">
        <b>AUTOGRAD</b> </span><br>
        <br>
        Thankfully, we can use automatic differentiation to automate the computation of 
        backward passes in neural networks.<br> The autograd package in PyTorch provides exactly 
        this functionality. <br>When using autograd, the forward pass of your network will define a 
        computational graph; nodes in the graph will be Tensors, and edges will be functions that 
        produce output Tensors from input Tensors. <br>Backpropagating through this graph then allows you 
        easily compute gradients.<br>
        <br>
        <span class="pyc2">
        x = torch.randn(bs, input, requires_grad=False) </span> # se False non si vuole che gradients venga calcolato automaticamente<br>
        y = torch.randn(bs, out, requires_grad=False)<br>
        dove bs indica numero batch size , input numero layer inseriti e output numero layer che si 
        ottengono dal modello con y che è il risultato e x i dati inseriti.<br><br>

        <span class="pyc2">
        weights1 = torch.randn(input, hidden, device=device, dtype=dtype, requires_grad=True)<br>
        weights2 = torch.randn(hidden, output, device=device, dtype=dtype, requires_grad=True)<br>
        <br></span>
        dtype=float, device=cpu/gpu/tpu requires_grad  calcolo automatico dei gradients <br>
        <br>
        y_pred = x.mm(weights1).clamp(min=0).mm(weights2) # con questa operazione otteniamo la previsione <br>
        del risultato atteso(forward)<br><br>

        loss = (y_pred - y).pow(2).sum() # qui otteniamo la perdita tra valore differenza <br>
        <br>
        <span class="blu">  loss.backward() </span># calcola i gradients per i tensor definiti con requires_grad=True 
        e li aggiorna con i nuovi valori per noi weights1 e weights2 e non x e y <br>
        <br>
        <span class="blu">
        with torch.no_grad():<br></span>
        usato quando nel context manager si usano tensor con requires_grad=True  e non si applica<br>
        backward quindi si calcolano gradients manualmente infatti <br>
        weights1 e  weights2 -= learning_rate *  weights1.grad e  weights2.grad e poi si azzerano i weights1/2.grad con <br>
        il comando weights1/2.grad.zero_() e si completano le iterazioni previste.<br>
        <br><br>
        <span class="titolo2">
         <b>
        NN module </b></span>  <br>
        <br>
        In PyTorch, i package nn sono dei moduli che contengono dei Layer come in TensorFlow per rendere più 
        agevole la costruzione di un modello di NN.<br> Ogni layer riceve in input 1 o più tensor e restituisce 
        altrettanti tensor in output.<br> Ci sono inoltre anche altre funzioni come le loss function. <br>
        <br>
        <span class="titolo2">
         <b>
        OPTIM package </b> </span>     <br> <br> <br>
        Questo package ci fornisce diverse funzioni contenti i diversi metodi di optimizer 
        come Stochastic Gradient Descent, AdaGrad, RMSProp, Adam ecc. <br><br>

        <span class="titolo2">
         <b>
        ESEMPIO MODELLO CON NN E OPTIM </b> </span>  <br><br><br>
      creo input ed output tensor <br>
      <br>
      <span class="blu">  model = torch.nn.Sequential(<br>
    torch.nn.Linear(input_layer , hidden_layer),<br>
    torch.nn.ReLU(),<br>
    torch.nn.Linear(hidden_layer, output_layer),<br>
)<br></span>
<br>
<span class="blu">loss_function = torch.nn.nn.CrossEntropyLoss()</span> <br>
<br>
learning_rate = 0.001<br>
<span class="blu">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br>
iteratore<br>
   y_pred = model(x)<br>

   <br>
   <span class="blu">loss = loss_function(y_pred, y)</span><br><br>
   <span class="blu"> optimizer.zero_grad() </span> #calcolo gradients <br>

   # Backward - calcolo gradient in base risultato loss function<br>
  
   <span class="blu">loss.backward()</span><br>

   # Optimizer update dati in base ai parametri del modello<br>

   <span class="blu">optimizer.step()</span><br>


   PyTorch: Custom nn Modules<br>

<div class="model">
   <span class="pyc">   class  </span> custumNet(torch.nn.Module):<br>
   <span style="margin-left:30px">     <span class="pyc">  def </span> __init__(self, input_dim, hidden_dim, out_dim):</span>  <br>

   <span style="margin-left:60px">            super(custumNet, self).__init__()</span>  <br>
   <span style="margin-left:60px">            self.l1 = torch.nn.Linear(input_dim, hidden_dim)</span>  <br>
      <span style="margin-left:60px">   self.l2 = torch.nn.Linear(hidden_dim, out_dim)</span>  <br>
          <br>
     <span style="margin-left:30px">   <span class="pyc">   def</span>  forward(self, x):</span>  <br>
    <span style="margin-left:60px">   """</span>  <br>
    <span style="margin-left:60px">  x è input tensor e y_pred è output tensor </span>  <br>
    <span style="margin-left:60px">  """</span>  <br>
    <span style="margin-left:60px">  relu = self.l1(x).clamp(min=0)</span>  <br>
     <span style="margin-left:60px">   y_pred = self.l2(relu) </span> <br>
    <span style="margin-left:60px">   return y_pred </span>  <br>
         <br>

 model = custumNet(input_dim, hidden_dim, out_dim)<br> 
</div>
   <br>
Nella sezione sottostante analizziamo un esempio di Convolutional Neural Network creato con PyTorch 
costruendo una class sia in sequentional che functional mode.
<br><br>
<div class="model">
import torch.nn as nn<br>
import torch.nn.functional as F<br>
import torch.optim as optim<br>
<br>

# sequentional model<br><br>

<span class="pyc"> class </span> SeqConvNet(nn.Module):<br>
<span style="margin-left:30px">   <span class="pyc">   def</span>  __init__(self):</span><br>
 <span style="margin-left:60px">      super(SeqConvNet, self).__init__()</span><br>
  <span style="margin-left:60px">        self.l1 = nn.Sequential(</span><br>
 <span style="margin-left:90px">            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=2),</span><br>
 <span style="margin-left:90px">             nn.ReLU(),</span><br>
 <span style="margin-left:90px">             nn.MaxPool2d(kernel_size=2, stride=2))</span><br>
  <span style="margin-left:60px">         self.l2 = nn.Sequential(</span><br>
 <span style="margin-left:90px">            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2),</span><br>
 <span style="margin-left:90px">             nn.ReLU(),</span><br>
 <span style="margin-left:90px">   nn.MaxPool2d(kernel_size=2, stride=2))</span><br>
 <span style="margin-left:60px"> self.l3 = nn.Dropout()</span><br>
 <span style="margin-left:60px"> self.l4 = nn.Linear(7 * 7 * 64, 1000)   # full connection layer</span><br>
 <span style="margin-left:60px"> self.l5 = nn.Linear(1000, 10)  # full connection layer</span><br>
  <br>
 <span style="margin-left:30px"> <span class="pyc">  def</span>  forward(self, x):   # x = input data</span><br>
  <span style="margin-left:60px"> out = self.l1(x)</span><br>
<span style="margin-left:60px"> out = self.l2(out)</span><br>
<span style="margin-left:60px"> out = out.reshape(out.size(0), -1)</span><br>
<span style="margin-left:60px"> out = self.l3(out)</span><br>
<span style="margin-left:60px"> out = self.l4(out)</span><br>
<span style="margin-left:60px"> out = self.l5(out)</span><br>
<span style="margin-left:60px"> return out</span><br>
<br>
# functional model <br>
<br>

<span class="pyc"> class </span> Model(nn.Module):<br>
<span style="margin-left:30px"> <span class="pyc"> def </span> __init__(self):</span><br>
 <span style="margin-left:60px">super(Model, self).__init__()</span><br>
 <span style="margin-left:60px">self.l1 = nn.Conv2d(1, 10, kernel_size=5)</span><br>
 <span style="margin-left:60px">self.l2 = nn.Conv2d(10, 20, kernel_size=5)</span><br>
 <span style="margin-left:60px">self.l3 = nn.Dropout2d(0.2)</span><br>
<span style="margin-left:60px"> self.l4 = nn.Linear(300, 50)</span><br>
<span style="margin-left:60px">self.l44 = nn.Dropout2d(0.2)</span><br>
 <span style="margin-left:60px">self.l5 = nn.Linear(50, 10)</span><br>
        <br>
        <span style="margin-left:30px"><span class="pyc">  def </span> forward(self, x):</span><br>
 <span style="margin-left:60px"> x = F.relu(F.max_pool2d(self.l1(x), 2))</span><br>
 <span style="margin-left:60px">x = F.relu(F.max_pool2d(self.l3(self.l2(x)), 2))</span><br>
  <span style="margin-left:60px"> x = x.view(-1, 320)</span><br>
  <span style="margin-left:60px"> x = F.relu(self.l4(x))</span><br>
  <span style="margin-left:60px">x = F.dropout(x, training=self.training)</span><br>
   <span style="margin-left:60px">x = self.l5(x)</span><br>
  <span style="margin-left:60px">x = self.l44(x)</span><br>
 <span style="margin-left:60px">return F.log_softmax(x)</span><br>
        <br>

model = Model()<br>
optimizer = <span class="pyc2">optim.SGD(model.parameters(), lr=learning_rate,<br>
   <span style="margin-left:60px">momentum=momentum)</span></span><br>
                              <br>

<span class="pyc"> def </span> train(epoch):<br>
<span style="margin-left:20px"><span class="pyc2">model.train() </span></span><br>
<span style="margin-left:20px">for batch_idx, (data, target) in enumerate(train_loader):</span><br>
<span style="margin-left:30px"><span class="pyc2">optimizer.zero_grad()</span></span><br>
   <span style="margin-left:30px">output =<span class="pyc2"> model(data)</span></span><br>
      <span style="margin-left:30px">loss = F.nll_loss(output, target)</span><br>
         <span style="margin-left:30px"><span class="pyc2"> loss.backward()</span> </span><br>
            <span style="margin-left:30px"><span class="pyc2"> optimizer.step()</span> </span><br>
      <span style="margin-left:30px">if batch_idx % log_interval == 0:</span><br>
      <span style="margin-left:60px">print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(</span><br>
          <span style="margin-left:60px">epoch, batch_idx * len(data), len(train_loader.dataset),</span><br>
          <span style="margin-left:60px">100. * batch_idx / len(train_loader), loss.item()))</span><br>
          <span style="margin-left:60px">train_losses.append(loss.item())</span><br>
          <span style="margin-left:60px">train_counter.append(</span><br>
          <span style="margin-left:90px">(batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))</span><br>
                                    <br>

<span class="pyc"> def </span> test():<br>
<span style="margin-left:30px"><span class="pyc2">model.eval()</span> </span><br>
   <span style="margin-left:30px">test_loss = 0</span><br>
      <span style="margin-left:30px">correct = 0</span><br>
         <span style="margin-left:30px">with <span class="pyc2">torch.no_grad()</span> :</span><br>
      <span style="margin-left:60px">for data, target in test_loader:</span><br>
            <span style="margin-left:90px">output = model(data)</span><br>
                 <span style="margin-left:90px">test_loss += <span class="pyc2"> F.nll_loss(output, target, size_average=False).item() </span></span><br>
                 <span style="margin-left:90px">pred = output.data.max(1, keepdim=True)[1]</span><br>
                  <span style="margin-left:90px">correct += pred.eq(target.data.view_as(pred)).sum()</span><br>
                 <span style="margin-left:90px">test_loss /= len(test_loader.dataset)</span><br>
                  <span style="margin-left:90px">test_losses.append(test_loss)</span><br>
                  <span style="margin-left:90px"> print('\nTest: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(</span><br>
                  <span style="margin-left:120px">test_loss, correct, len(test_loader.dataset),</span><br>
                     <span style="margin-left:120px">100. * correct / len(test_loader.dataset)))</span><br>
<br>

<br>
for epoch in range(1, n_epochs + 1):<br>
<span style="margin-left:30px">train(epoch)</span><br>
<span style="margin-left:30px">test()</span><br>


</div>

Vediamo come costruire un layer lineare inserendo i dati a nostro piacere confermando però 
i metodi init e forward.<br> Inserendo il layer sottostante nel modello presentato in precedenda come 
fc2, secondo full connected layer si ottiene una accuracy nella fase di test del 99,02%.<br>
Questa la struttura del modello creato :<br><br>


ConvNet(<br>
   <span style="margin-left:30px">  (layer1): Sequential(</span><br>
      <span style="margin-left:60px">    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br>
         <span style="margin-left:60px">      (1): ReLU()</span><br>
            <span style="margin-left:60px">      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br>
               <span style="margin-left:30px">  )</span><br>
                  <span style="margin-left:30px"> (layer2): Sequential(</span><br>
   <span style="margin-left:60px">     (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br>
      <span style="margin-left:60px">      (1): ReLU()</span><br>
         <span style="margin-left:60px">      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br>
            <span style="margin-left:30px">  )</span><br>
  <span style="margin-left:60px">    (drop_out): Dropout(p=0.5, inplace=False)</span><br>
   <span style="margin-left:60px">    (fc1): Linear(in_features=3136, out_features=1000, bias=True)</span><br>
      <span style="margin-left:60px">    (fc2): CustomLayer()</span><br>
         <span style="margin-left:30px">)</span><br>






<div class="model">


   <span class="pyc"> class </span> CustomLayer(nn.Module):<br>
<span style="margin-left:30px">    """ Custom Linear layer  """</span><br>
<span style="margin-left:30px"> <span class="pyc">  def </span> __init__(self, in_dim, out_dim):</span><br>
<span style="margin-left:60px">        super().__init__()</span><br>
<span style="margin-left:60px">       self.in_dim, self.out_dim = in_dim, out_dim</span><br>
<span style="margin-left:60px">       weights = torch.Tensor(out_dim, in_dim)</span><br>
 <span style="margin-left:60px">       self.weights = nn.Parameter(weights)  </span><br>
 <span style="margin-left:60px">        bias = <span class="pyc2">torch.Tensor(out_dim)</span> </span><br>
<span style="margin-left:60px">        self.bias = <span class="pyc2">nn.Parameter(bias)</span></span><br>

<span style="margin-left:60px">        # ora si inizializzano weights(w) e biases(b)</span><br>
 <span style="margin-left:60px">  <span class="pyc2">  nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))</span> # weight init</span><br>
 <span style="margin-left:60px">        fan_in, _ =<span class="pyc2"> nn.init._calculate_fan_in_and_fan_out(self.weights)</span></span><br>
<span style="margin-left:60px">        bound = 1 / math.sqrt(fan_in)</span><br>
 <span style="margin-left:60px"> <span class="pyc2">      nn.init.uniform_(self.bias, -bound, bound)</span>  # bias init</span><br>

 <span style="margin-left:30px"> <span class="pyc">   def </span> forward(self, x):</span><br>
<span style="margin-left:60px">        wx= <span class="pyc2">torch.mm(x, self.weights.t())</span></span><br>
<span style="margin-left:60px">        return torch.add(wx, self.bias)  # w * x + b   cost function</span><br>
  
<br><br>


plt.plot(loss_list,'b')<br>
plt.plot(loss_test,'y')<br>
plt.ylabel('Loss')<br>
plt.show()<br>
<br><br>
<img src="foto/torch1.png" width="50%" height="300px">
<br><br><br>
plt.plot(acc_list,'m')<br>
plt.ylabel('accuracy')<br>
plt.show()<br><br>
<br><br>
<img src="foto/torch2.png" width="50%" height="300px">
<br><br>
</div>



















</div>
</body>



</html>
      