
<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0" />
    <meta name="google-site-verification" content="VXixwtxrf--qUV1swfStEg9jOGPKgUm6C3Ub_vouqmc" />
    <title>MecBar | The Mec Evolution </title>
    <link rel="icon" href="foto/favicon.ico"/>
    <!-- CSS  -->
    <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection" />
    
    <script src="js/jquery-3.js"></script>
    
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
   
    <link href="https://fonts.googleapis.com/css?family=Raleway|Satisfy" rel="stylesheet">
    <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection" />

    <link href="css/style2.css" type="text/css" rel="stylesheet" media="screen,projection" />
    <link href="css/navbar.css" type="text/css" rel="stylesheet" media="screen,projection" />
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital@1&display=swap" rel="stylesheet"> 
</head>
<header>
    <nav>
        <li class="nav-wrapper back-home" id="head">
            <a href="http://www.mecbar.com/" class="brand-logo mecbar">
                <?xml version="1.0" encoding="UTF-8" standalone="no"?>
                <svg
                   xmlns:osb="http://www.openswatchbook.org/uri/2009/osb"
                   xmlns:dc="http://purl.org/dc/elements/1.1/"
                   xmlns:cc="http://creativecommons.org/ns#"
                   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                   xmlns:svg="http://www.w3.org/2000/svg"
                   xmlns="http://www.w3.org/2000/svg"
                   xmlns:xlink="http://www.w3.org/1999/xlink"
                   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
                   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
                   width="156"
                   height="64"
                   viewBox="0 0 12.3825 5.08"
                   version="1.1"
                   id="svg8"
                   inkscape:version="1.0 (6e3e5246a0, 2020-05-07)"
                   sodipodi:docname="mecbar.svg">
                  <defs
                     id="defs2">
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient2948">
                      <stop
                         id="stop2946"
                         offset="0"
                         style="stop-color:#c6126a;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient875">
                      <stop
                         id="stop873"
                         offset="0"
                         style="stop-color:#babd06;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3253"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#878734;stop-opacity:1;"
                         offset="0"
                         id="stop3251" />
                    </linearGradient>
                    <linearGradient
                       inkscape:collect="always"
                       id="linearGradient3093">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3089" />
                      <stop
                         style="stop-color:#c6126a;stop-opacity:0;"
                         offset="1"
                         id="stop3091" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3071"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3069" />
                    </linearGradient>
                    <rect
                       x="38.182308"
                       y="80.104469"
                       width="51.135052"
                       height="30.274338"
                       id="rect18630" />
                    <rect
                       x="160.31746"
                       y="77.487633"
                       width="134.35785"
                       height="60.829021"
                       id="rect18624" />
                    <rect
                       x="70.354279"
                       y="28.223705"
                       width="103.27115"
                       height="64.638908"
                       id="rect18618" />
                    <rect
                       x="32.55666"
                       y="25.199898"
                       width="5.2916665"
                       height="43.089287"
                       id="rect18612" />
                    <rect
                       x="34.029621"
                       y="65.792862"
                       width="93.441322"
                       height="26.673161"
                       id="rect18606" />
                    <rect
                       x="10.284417"
                       y="19.486744"
                       width="193.27823"
                       height="129.88597"
                       id="rect18596" />
                    <linearGradient
                       inkscape:collect="always"
                       xlink:href="#linearGradient3093"
                       id="linearGradient3101"
                       gradientUnits="userSpaceOnUse"
                       x1="3.1346149"
                       y1="23.792595"
                       x2="78.606865"
                       y2="23.792595" />
                    <filter
                       height="1"
                       y="-2.5183475e-16"
                       width="1"
                       x="-7.1910066e-17"
                       style="color-interpolation-filters:sRGB"
                       inkscape:label="Blend"
                       id="filter3198">
                      <feBlend
                         in2="SourceGraphic"
                         mode="multiply"
                         result="fbSourceGraphic"
                         id="feBlend3196" />
                      <feColorMatrix
                         result="fbSourceGraphicAlpha"
                         in="fbSourceGraphic"
                         values="0 0 0 -1 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0 1 0"
                         id="feColorMatrix3200" />
                      <feBlend
                         in2="fbSourceGraphic"
                         id="feBlend3202"
                         mode="multiply"
                         result="blend"
                         in="fbSourceGraphic" />
                      <feGaussianBlur
                         id="feGaussianBlur869"
                         stdDeviation="6.7542215e-15" />
                    </filter>
                    <linearGradient
                       gradientUnits="userSpaceOnUse"
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       id="linearGradient2950"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                    <linearGradient
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       gradientTransform="translate(2.3455617,-9.683066)"
                       gradientUnits="userSpaceOnUse"
                       id="linearGradient3064"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                  </defs>
                  <sodipodi:namedview
                     id="base"
                     pagecolor="#ffffff"
                     bordercolor="#666666"
                     borderopacity="1.0"
                     inkscape:pageopacity="0.0"
                     inkscape:pageshadow="2"
                     inkscape:zoom="0.7"
                     inkscape:cx="355.19772"
                     inkscape:cy="45.714286"
                     inkscape:document-units="mm"
                     inkscape:current-layer="layer1-6"
                     inkscape:document-rotation="0"
                     showgrid="false"
                     inkscape:window-width="1324"
                     inkscape:window-height="747"
                     inkscape:window-x="36"
                     inkscape:window-y="21"
                     inkscape:window-maximized="1"
                     units="px"
                     inkscape:snap-nodes="true"
                     inkscape:object-paths="true"
                     scale-x="0.3" />
                  <metadata
                     id="metadata5">
                    <rdf:RDF>
                      <cc:Work
                         rdf:about="">
                        <dc:format>image/svg+xml</dc:format>
                        <dc:type
                           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
                        <dc:title></dc:title>
                      </cc:Work>
                    </rdf:RDF>
                  </metadata>
                  <g
                     inkscape:label="Layer 1"
                     inkscape:groupmode="layer"
                     class="io"
                     id="layer1">
                    <rect
                       ry="7.1295023"
                       rx="10.726023"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="21.245117"
                       width="20.103241"
                       id="rect2824"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                    <g
                       inkscape:label="Layer 1"
                       id="layer1-6"
                       transform="matrix(0.16152221,0.0020121,0,0.13626925,0.08059628,0.86541284)"
                       style="mix-blend-mode:normal;fill:url(#linearGradient2950);fill-opacity:1;stroke-width:6.74038;filter:url(#filter3198);image-rendering:optimizeQuality">
                      <text
                         xml:space="preserve"
                         id="text18594"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18596);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;line-height:125%;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;letter-spacing:0px;word-spacing:0px;fill:url(#linearGradient3064);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
                         x="-4.0898471"
                         y="24.876211"
                         id="text18602"
                         transform="matrix(0.75566848,-0.20637119,0.34609071,1.2288151,0,0)"><tspan
                   sodipodi:role="line"
                   id="tspan18600"
                   x="-4.0898471"
                   y="24.876211"
                   style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:url(#linearGradient3064);fill-opacity:1;stroke-width:1.78339px">MecBar</tspan>        <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="0s;light_2.end"
                   dur="1s"
                   values="1;0"
                   attributeName="fill-opacity"
                   id="light_1" />       <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="light_1.end"
                   dur="1s"
                   values="0;1"
                   attributeName="fill-opacity"
                   id="light_2" />           </text>
                      <text
                         xml:space="preserve"
                         id="text18604"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18606);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18610"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18612);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18616"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18618);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18622"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18624);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18628"
                         style="font-style:normal;font-weight:normal;font-size:12.7px;line-height:125%;font-family:sans-serif;text-align:justify;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18630);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="0s;light_2.end"
                         dur="1s"
                         values="1;0"
                         attributeName="fill-opacity"
                         id="light_1" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="light_1.end"
                         dur="1s"
                         values="0;1"
                         attributeName="fill-opacity"
                         id="light_2" />
                    </g>
                    <rect
                       ry="7.1295042"
                       rx="10.726021"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="16.413473"
                       width="25.987757"
                       id="rect871"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                  </g>
                  <style
                     id="style43">
                           #tspan18600 {
                               
                              animation-name: mecOpacity;
                              animation-duration: 2s;
                              animation-iteration-count: infinite;
                              }
                              @keyframes mecOpacity {
                              0%   { fill-opacity:1 }
                                50%  {fill-opacity :0.1; }
                            100% { fill-opacity: 1; }
                              }
                    </style>
                </svg>
                </a>
            <a href="#" data-activates="mobile-demo" class="button-collapse"><i class="material-icons">menu</i></a>

            <ul class="right hide-on-med-and-down">
                <!--  <li> <a class="btn" onclick="Materialize.toast('Hello', 4000, 'Ciao' ,4000 )">Touch Me</a> </li>
              -->

              <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
              <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
                <li>
                    <a href=""> </a>
                </li>
                <li>
                    <a href=""> </a>
                </li>
            </ul>
          
              <ul class="side-nav" id="mobile-demo">
               <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
                 <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
            </ul>
        
            </li>
    </nav>
</header>
<script>
    MathJax = {
      loader: {load: ['input/asciimath', 'output/chtml']}
    }
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<div class="center titolo">
    <i>TRANSFORMER - MULTI-HEAD ATTENTION - SEQtoSEQ Translation    </i>
 </div>
 <div class="testo">
    Per effettuare dei modelli Sequence to Sequence è stato creato un nuovo modello 
    denominato Transformer che qui verrà riprodotto in base al paper <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> che qui utilizziamo con PyTorch 
    e vedremo un esempio di come costruire un modello per il language translation dove inserendo una sequenza di parole in italiano verranno tradotte in inglese. 
    <br>
    Le diverse fasi sono : <br>
    Creazione <b>input data </b><br>
    <b>Input Embedding</b> # convertire input token in vector<br>
    <b>Positional Encoding </b># informazioni relative alla posizione del token nella sentence<br>
    <b>Attention </b> # funzione per mapping di q e set di k-v pairs dove q sta per query, k per key e v per values
    <br> <b>Encoder</b> # con 6 layer identici <br> 
    <b>Decoder</b> # con 6 layer identici<br>
    <b>Multi-Head Attention </b><br>
    <b> Normalization </b># creare dati più omogenei per facilitare i calcoli<br>
    <b>Feed Forward </b><br>
    <b> Output Embedding </b><br>
    <br>
    Nel grafico sono rappresentate le sequenze delle diverse fasi. 
  
    Partendo da sinistra si trova il Transformer.
    Da notare che i dati prodotti dall'Encoder poi vengono passati in input al Decoder insieme ai dati propri del decoder per poi ottenere dopo altri layer 
    output che ha la maggiore probabilità.   <br>
    Passiamo al grafico al centro dove sono riprodotte le operazioni che creano il Multi-Head Attention. Nell'esempio sottostante si creano 8 
    head Attention come riportato nel paper sopra indicato.
     <br>Infine a destra troviamo le operazioni che si effettuano nel processo Scaled Dot Product.<br><br><br>
     <br><br><br>
<div class="row blog-box">
    <div class="col l6 center">
     Transformer<br> <br> <br>
    <img src="foto/transformer_architecture.jpg" width="100%" height="500px">
    </div>
    <div class="col l3 center">
Multi-Head Attention Layer <br> <br> <br> <br> <br>

    <img src="foto/multiheadattention.png" width="70%" height="300px">
    </div>
<div class="col l3 center">
    Scaled Dot Product Attention <br> <br> <br> <br> <br>
    <img src="foto/scaledDot.png" width="30%" height="300px"> 
</div>
</div>
    <br>
    <br>
    Input <br><br>
 Per importare i dati usiamo la funzione TORCHTEXT che ci consente di importare i dati e di creare dei 
 dictonary con l'elenco delle parole delle 2 lingue. Da notare che le parole inserite vengono 
 poi trasformate in tensor che poi con il metodo transpose da orizzontali diventano verticali ad es. 
 [0,1] diviene<br> [0,<br>
                1]<br>
 Con spacy importiamo un oggetto che ci consente di gestire le parole nelle 2 lingue che vogliamo utilizzare.
 <br>
 <div class="model4">
 en = spacy.load('en')<br>
it = it_core_news_sm.load()<br>

<br>
IT = Field(tokenize=tokenizerIT,init_token = "&lt;sos&gt;", eos_token = "&lt;eos&gt;")<br>
EN = Field(tokenize=tokenizerEN, init_token = "&lt;sos&gt;", eos_token = "&lt;eos&gt;")<br>
 </div>
Per importare i dati usiamo la funzione TabularDataset di TORCHTEXT che ci consente di creare dei blocchi di dati 
divisi in batch. Prima però dividiamo il DataFrame df in una perte per la fwase di training e una parte per 
fase di test del moddello. <br>
<div class="model5">
trainItaEn, testItaEn = train_test_split(df, test_size=0.1) # split input file in 2 parti<br>
<br>
train,test = TabularDataset.splits(path='./', train='train.csv', validation='test.csv', format='csv',
                                   fields=[('IT', IT), ('EN', EN)])<br>
train.fields<br>
{'EN': &lt;torchtext.data.field.Field at 0x7f527d131668&gt;,<br>
    'IT': &lt;torchtext.data.field.Field at 0x7f5291452048&gt;}<br>
    </div>
Creazione di due vocabolari.<br>
<div class="model4">
IT.build_vocab(train, test)<br>
EN.build_vocab(train, test)<br>
IT.vocab.itos<br>
</div>
con questo comando vediamo la lista creata con i simboli iniziali e tutte le parole inserite nelle frasi in italiano. <br>
<div class="model5">
['&lt;unk&gt;','&lt;pad&gt;','&lt;sos&gt;','&lt;eos&gt;','.','Tom','?','è','di','a','non','che',   .... ]<br><br>
</div>
<div class="model4">
    IT.vocab.stoi<br>
</div>
con questo comando vediamo il dictonary creato con i simboli iniziali e parole inserite nelle frasi in italiano. <br>
<div class="model5">
defaultdict(&lt;function torchtext.vocab._default_unk_index&gt;)<br>
 {'&lt;unk&gt;': 0,'&lt;pad&gt;': 1,'&lt;sos&gt;': 2,'&lt;eos&gt;': 3,'.': 4,'Tom': 5,'?': 6,'è': 7, 'di': 8,'a': 9,'non': 10,'che': 11 .... }
</div>
<div class="model5">
EN.vocab.itos<br>
</div>
con questo comando vediamo la lista creata con i simboli iniziali e tutte le parole inserite nelle frasi in inglese. 
<div class="model4">
 ['&lt;unk&gt;', '&lt;pad&gt;', '&lt;sos&gt;', '&lt;eos&gt;', '.', 'I', 'Tom', 'you', 'to', '?', "n't", 'the', ...]
</div>
<div class="model5">
EN.vocab.stoi
</div>
con questo comando vediamo il dictonary creato con i simboli iniziali e parole inserite nelle frasi in inglese. 
<div class="model4">
defaultdict(&lt;function torchtext.vocab._default_unk_index&gt;,<br>
    <br>{'&lt;unk&gt;': 0,'&lt;pad&gt;': 1,'&lt;sos&gt;': 2,'&lt;eos&gt;': 3,'.': 4,'I': 5,'Tom': 6,'you': 7,'to': 8,'?': 9, "n't": 10,'the': 11, .... }
</div>
Creazione di un iterator con BucketIterator funzione di TORCHTEXT con un bacth-size di 32 record <br>
<div class="model5">
trainI = BucketIterator(train, batch_size=32,shuffle= True)<br>
</div>
<br><br>
Ora il programma completo con importazione di un file composto da frasi in italiano e relativa traduzione in inglese. 
<br><br>

<div class="model4">
!python -m spacy download it_core_news_sm<br>
import torch<br>
import torch.nn as nn<br>
import torch.nn.functional as F<br>
import pandas as pd<br>
import spacy<br>
import torchtext<br>
from torchtext.data import Field, BucketIterator, TabularDataset <br>
from torch.autograd import Variable<br>
import math, copy<br>
import it_core_news_sm<br>
from sklearn.model_selection import train_test_split<br>
import numpy as np<br>
</div>
<div class="model5">
class Embedding(nn.Module):<br>
<span style="margin-left:30px">def __init__(self, vocab_size, dModel):</span><br>
<span style="margin-left:60px"> super().__init__()</span><br>
 <span style="margin-left:60px"> self.embedding = nn.Embedding(vocab_size, dModel)</span><br>
 <span style="margin-left:30px">def forward(self, x):</span><br>
<span style="margin-left:60px">embedding = self.embedding.to(device)</span><br>
 <span style="margin-left:60px">return embedding(x)</span><br>
</div>
 <div class="model5">
class PositionalEncoder(nn.Module):<br>
<span style="margin-left:30px">def __init__(self, dModel, max_seq_len = 180):</span><br>
    <span style="margin-left:60px">super().__init__()</span><br>
  <span style="margin-left:60px">self.dModel = dModel</span><br>
            
 <span style="margin-left:60px">posEnc = torch.zeros(max_seq_len, dModel ,device = device)</span><br>
 <span style="margin-left:60px">for posit in range(max_seq_len):</span><br>
  <span style="margin-left:90px">for i in range(0, dModel, 2):</span><br>
 <span style="margin-left:120px">posEnc[posit, i] = math.sin(posit / (10000 ** ((2 * i)/dModel)))</span><br>
 <span style="margin-left:120px"> posEnc[posit, i + 1] = math.cos(posit / (10000 ** ((2 * (i + 1))/dModel)))</span><br>
                    
 <span style="margin-left:60px">posEnc = posEnc.unsqueeze(0)</span><br>
  <span style="margin-left:60px">self.register_buffer('posEnc', posEnc)</span><br>
     
        
 <span style="margin-left:30px">def forward(self, x):</span><br>
 <span style="margin-left:60px">x = x.to(device)</span><br>
  <span style="margin-left:60px"> x = x * math.sqrt(self.dModel)</span><br>
<span style="margin-left:60px"> seqLength= x.size(1)</span><br>
    <span style="margin-left:60px"> x = x + Variable(self.posEnc[:,:seqLength],requires_grad=False).to(device)</span><br>
<span style="margin-left:60px"> return x</span><br>
</div>

<div class="model5">
 class MultiHeadAttention(nn.Module):<br>
 <span style="margin-left:30px">def __init__(self, numHead, dModel, dropout = 0.1):</span><br>
 <span style="margin-left:60px">super().__init__()   </span><br>    
  <span style="margin-left:60px"> self.dModel = dModel</span><br>
 <span style="margin-left:60px">self.d_k = dModel // numHead</span><br>
 <span style="margin-left:60px"> self.h = numHead    </span><br>       
 <span style="margin-left:60px"> self.q = nn.Linear(dModel, dModel)</span><br>
  <span style="margin-left:60px">self.v = nn.Linear(dModel, dModel)</span><br>
 <span style="margin-left:60px">self.k = nn.Linear(dModel, dModel)</span><br>
 <span style="margin-left:60px">self.dropout = nn.Dropout(dropout)</span><br>
 <span style="margin-left:60px">self.output = nn.Linear(dModel, dModel)   </span><br> 
<span style="margin-left:30px">def forward(self, q, k, v, mask=None):  </span><br>      
 <span style="margin-left:60px"> bs = q.size(0)      </span><br>  
 <span style="margin-left:60px"># perform linear operation and split into h numHead   </span><br>        
 <span style="margin-left:60px">k = self.k(k).view(bs, -1, self.h, self.d_k)</span><br>
 <span style="margin-left:60px"> k = k.to(device)</span><br>
  <span style="margin-left:60px">q = self.q(q).view(bs, -1, self.h, self.d_k)</span><br>
 <span style="margin-left:60px">q = q.to(device)</span><br>
  <span style="margin-left:60px"> v = self.v(v).view(bs, -1, self.h, self.d_k)</span><br>
 <span style="margin-left:60px"> v = v.to(device)</span><br>
<span style="margin-left:60px"> # transpose to get dimensions bs * h * sl * dModel</span><br>
<span style="margin-left:60px"> k = k.transpose(1,2)</span><br>
 <span style="margin-left:60px">q = q.transpose(1,2)</span><br>
 <span style="margin-left:60px">v = v.transpose(1,2)</span><br>
 <span style="margin-left:60px">scores = attention(q, k, v, self.d_k, mask, self.dropout)</span><br>
 <span style="margin-left:60px">concat = scores.transpose(1,2).contiguous().view(bs, -1, self.dModel)   </span><br>           
  <span style="margin-left:60px">output = self.output(concat)     </span><br>    
 <span style="margin-left:60px"> return output</span><br>
</div>
<div class="model5">

class FeedForward(nn.Module):<br>
<span style="margin-left:30px">def __init__(self, dModel, d_ff=2048, dropout = 0.1):</span><br>
<span style="margin-left:60px">super().__init__() </span><br>
<span style="margin-left:60px">self.linear1 = nn.Linear(dModel, d_ff)</span><br>
 <span style="margin-left:60px"> self.dropout = nn.Dropout(dropout)</span><br>
  <span style="margin-left:60px"> self.linear2 = nn.Linear(d_ff, dModel)</span><br>
 <span style="margin-left:30px">def forward(self, x):</span><br>
 <span style="margin-left:60px"> x = self.dropout(F.relu(self.linear1(x)))</span><br>
 <span style="margin-left:60px"> x = self.linear2(x)</span><br>
  <span style="margin-left:60px"> x = x.to(device)</span><br>
   <span style="margin-left:60px"> return x</span><br>
</div>

<div class="model5">
class Normalisation(nn.Module):<br>
<span style="margin-left:30px">def __init__(self, dModel, eps = 1e-6):</span><br>
 <span style="margin-left:60px">super().__init__()</span><br>
        
  <span style="margin-left:60px">self.size = dModel</span><br>
  <span style="margin-left:60px">self.alpha = nn.Parameter(torch.ones(self.size))</span><br>
 <span style="margin-left:60px">self.bias = nn.Parameter(torch.zeros(self.size))</span><br>
  <span style="margin-left:60px"> self.eps = eps</span><br>
 <span style="margin-left:30px">def forward(self, x):</span><br>
    <span style="margin-left:60px"> norm = self.alpha * (x - x.mean(dim=-1, keepdim=True))/(x.std(dim=-1, keepdim=True) + self.eps) + self.bias</span><br>
   <span style="margin-left:60px">return norm.to(device)</span><br>

class EncoderLayer(nn.Module):<br>
<span style="margin-left:30px">def __init__(self, dModel, numHead, dropout = 0.1):</span><br>
<span style="margin-left:60px">super().__init__()</span><br>
<span style="margin-left:60px">self.norm1 = Normalisation(dModel)</span><br>
<span style="margin-left:60px"> self.norm2 = Normalisation(dModel)</span><br>
<span style="margin-left:60px"> self.mhattention = MultiHeadAttention(numHead, dModel)</span><br>
<span style="margin-left:60px">self.ff = FeedForward(dModel)</span><br>
<span style="margin-left:60px">self.dropout1 = nn.Dropout(dropout)</span><br>
                
  <span style="margin-left:30px"> def forward(self, x, mask):</span><br>
  <span style="margin-left:60px"> xNorm = self.norm1(x)</span><br>
  <span style="margin-left:60px"> x = x + self.dropout1(self.mhattention(xNorm,xNorm,xNorm,mask))</span><br>
  <span style="margin-left:60px"> xNorm = self.norm2(x)</span><br>
  <span style="margin-left:60px"> x = x + self.dropout1(self.ff(xNorm))</span><br>
  <span style="margin-left:60px"> return x.to(device)</span><br>
</div>
<div class="model5">           
    
class DecoderLayer(nn.Module):<br>
<span style="margin-left:30px"> def __init__(self, dModel, numHead, dropout=0.1):</span><br>
            <span style="margin-left:60px">super().__init__()</span><br>
            <span style="margin-left:60px"> self.norm_1 = Normalisation(dModel)</span><br>
            <span style="margin-left:60px">self.norm_2 = Normalisation(dModel)</span><br>
            <span style="margin-left:60px"> self.norm_3 = Normalisation(dModel)</span><br>
                
            <span style="margin-left:60px"> self.dropout_1 = nn.Dropout(dropout)</span><br>
            <span style="margin-left:60px"> self.dropout_2 = nn.Dropout(dropout)</span><br>
            <span style="margin-left:60px">self.dropout_3 = nn.Dropout(dropout)</span><br>
                
            <span style="margin-left:60px"> self.attn_1 = MultiHeadAttention(numHead, dModel)</span><br>
            <span style="margin-left:60px">self.attn_2 = MultiHeadAttention(numHead, dModel)</span><br>
            <span style="margin-left:60px">self.ff = FeedForward(dModel).to(device)</span><br>
 <span style="margin-left:30px">def forward(self, x, encOut, sourceMask, targetMask):</span><br>
 <span style="margin-left:60px">x2 = self.norm_1(x)</span><br>
 <span style="margin-left:60px">x2 = x2.to(device)</span><br>
 <span style="margin-left:60px">x = x + self.dropout_1(self.attn_1(x2, x2, x2, targetMask))</span><br>
 <span style="margin-left:60px">x = x.to(device)</span><br>
 <span style="margin-left:60px"> x2 = self.norm_2(x)</span><br>
 <span style="margin-left:60px"> x = x + self.dropout_2(self.attn_2(x2, encOut, encOut, sourceMask))</span><br>
 <span style="margin-left:60px"> x2 = self.norm_3(x)</span><br>
 <span style="margin-left:60px"> x = x + self.dropout_3(self.ff(x2))</span><br>
 <span style="margin-left:60px"> return x</span><br>
             
</div>

<div class="model5">
class Encoder(nn.Module):<br>
<span style="margin-left:30px"> def __init__(self, vocab_size, dModel, N, numHead):</span><br>
<span style="margin-left:60px">super().__init__()</span><br>
<span style="margin-left:60px">self.N = N</span><br>
<span style="margin-left:60px">self.embed = Embedding(vocab_size, dModel)</span><br>
<span style="margin-left:60px">self.pe = PositionalEncoder(dModel)</span><br>
<span style="margin-left:60px"> self.layers = cloneModule(EncoderLayer(dModel, numHead), N)</span><br>
<span style="margin-left:60px"> self.norm = Normalisation(dModel)</span><br>
<span style="margin-left:30px">def forward(self, source, mask):</span><br>
<span style="margin-left:60px"> x = self.embed(source)</span><br>
<span style="margin-left:60px"> x = self.pe(x)</span><br>
<span style="margin-left:60px">for i in range(N):</span><br>
<span style="margin-left:90px">x = self.layers[i](x, mask)</span><br>
<span style="margin-left:60px">return self.norm(x)</span><br>
</div>
<div class="model5">                
class Decoder(nn.Module):<br>
<span style="margin-left:30px">def __init__(self, vocab_size, dModel, N, numHead):</span><br>
<span style="margin-left:60px">super().__init__()</span><br>
<span style="margin-left:60px">self.N = N</span><br>
<span style="margin-left:60px">self.embed = Embedding(vocab_size, dModel)</span><br>
<span style="margin-left:60px">self.pe = PositionalEncoder(dModel)</span><br>
<span style="margin-left:60px">self.layers = cloneModule(DecoderLayer(dModel, numHead), N)</span><br>
<span style="margin-left:60px">self.norm = Normalisation(dModel)</span><br>
 <span style="margin-left:30px"> def forward(self, trg, encOut, sourceMask, targetMask):</span><br>
 <span style="margin-left:60px"> x = self.embed(trg)</span><br>
 <span style="margin-left:60px"> x = self.pe(x)</span><br>
 <span style="margin-left:60px"> for i in range(self.N):</span><br>
 <span style="margin-left:90px"> x = self.layers[i](x, encOut, sourceMask, targetMask)</span><br>
 <span style="margin-left:60px">return self.norm(x)</span><br>
</div>
<div class="model5">
class Transformer(nn.Module):<br>
<span style="margin-left:63px">def __init__(self, len_src_vocab, len_trg_vocab, dModel, N, numHead):</span><br>
<span style="margin-left:60px">super().__init__()</span><br>
<span style="margin-left:60px">self.encoder = Encoder(len_src_vocab, dModel, N, numHead).to(device)</span><br>
<span style="margin-left:60px">self.decoder = Decoder(len_trg_vocab, dModel, N, numHead).to(device)</span><br>
<span style="margin-left:60px">self.out = nn.Linear(dModel, len_trg_vocab)</span><br>
<span style="margin-left:30px">def forward(self, source, target, sourceMask, targetMask):</span><br>
<span style="margin-left:60px">source = source.to(device)</span><br>
<span style="margin-left:60px">target = target.to(device)</span><br>
<span style="margin-left:60px"> sourceMask.to(device)</span><br>
<span style="margin-left:60px">targetMask.to(device)</span><br>
<span style="margin-left:60px"> encOut = self.encoder(source, sourceMask)</span><br>
<span style="margin-left:60px"> encOut.to(device)</span><br>
<span style="margin-left:60px">decOutput = self.decoder(target, encOut, sourceMask, targetMask)</span><br>
<span style="margin-left:60px"> decOutput.to(device)</span><br>
<span style="margin-left:60px">return self.out(decOutput).to(device)</span><br>
                 
</div>
<div class="model5">
def tokenizerIT(frasi):<br>
<span style="margin-left:60px">return [token.text for token in it.tokenizer(frasi)]</span><br>
                        
def tokenizerEN(frasi):<br>
<span style="margin-left:60px">return [token.text for token in en.tokenizer(frasi)] </span><br>                       

def cloneModule(module, N):<br>
<span style="margin-left:60px">return nn.ModuleList([copy.deepcopy(module) for i in range(N)])</span><br>


def attention(q, k, v, d_k, mask=None, dropout=None):
    
<span style="margin-left:30px">scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)</span><br>
<span style="margin-left:30px">if mask is not None:</span><br>
    <span style="margin-left:60px">mask = mask.unsqueeze(1).to(device)</span><br>
    <span style="margin-left:60px"> scores = scores.masked_fill(mask == 0, -1e9).to(device)</span><br>
    <span style="margin-left:60px">scores = F.softmax(scores, dim=-1)</span><br>
    
    <span style="margin-left:30px">if dropout is not None:</span><br>
    <span style="margin-left:60px">scores = dropout(scores)</span><br>
    
    <span style="margin-left:30px">return torch.matmul(scores, v).to(device)</span><br>


def creaMask(src, trg):

<span style="margin-left:30px">inputSeq = src</span><br>
<span style="margin-left:30px"> inputPad = IT.vocab.stoi['&lt;pad&gt;']  </span><br>
<span style="margin-left:30px"> # se pad inserisce 0  </span><br>
<span style="margin-left:30px">inputMask = (inputSeq != inputPad).unsqueeze(1)</span><br>
<span style="margin-left:30px"> targetSeq = trg</span><br>
<span style="margin-left:30px">targetPad = EN.vocab.stoi['&lt;pad&gt;']</span><br>
<span style="margin-left:30px">targetMask = (targetSeq != targetPad).unsqueeze(1)</span><br>
<span style="margin-left:30px">targetMask = targetMask.to(device)</span><br>
<span style="margin-left:30px"> mask = np.triu(np.ones((1, targetSeq.size(1) , targetSeq.size(1) )), k=1).astype('uint8')</span><br>
<span style="margin-left:30px">mask = Variable(torch.from_numpy(mask) == 0).to(device)</span><br>
<span style="margin-left:30px">targetMask = targetMask & mask</span><br>
<span style="margin-left:30px">return inputMask, targetMask , targetPad </span><br>

</div>


<div class="model5">
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")<br>
    filename = "....../ita.txt"<br>
    data = pd.read_csv(filename, sep='\t')<br>
    eng = data.iloc[:,0]<br>
    ita = data.iloc[:,1]<br>
    df = pd.DataFrame({'IT':ita,'EN':eng })<br>
    <br>
    with open('ita-eng.txt', 'w') as f:<br>
    <span style="margin-left:60px"> f.write( df.to_csv(header = False, index = False)  )</span><br>
        <br>
    
    en = spacy.load('en')<br>
    
    <br>
    it = it_core_news_sm.load()<br>
    <br>
    IT = Field(tokenize=tokenizerIT, init_token = "&lt;sos&gt;", eos_token = "&lt;eos&gt;")<br>
    EN = Field(tokenize=tokenizerEN, init_token = "&lt;sos&gt;", eos_token = "&lt;eos&gt;")<br>
  
    trainItaEn, testItaEn = train_test_split(df, test_size=0.1)<br>
    <br>
    trainItaEn.to_csv("train.csv", index=False)<br>
    testItaEn.to_csv("test.csv", index=False)<br>
    <br>
    train,test = TabularDataset.splits(path='./', train='train.csv', validation='test.csv', format='csv',<br>
    <span style="margin-left:60px">  fields=[('IT', IT), ('EN', EN)])</span><br>
          <br>
    IT.build_vocab(train, test)<br>
    EN.build_vocab(train, test)<br>
    <br>
    trainI = BucketIterator(train, batch_size=32,shuffle= True)<br>
    
</div>


<div class="model5">

    EPOCHS = 4<br>
    max_sequence_length = 180<br>
    dModel = 512   # input e output dimension<br>
    d_ff=2048  # inner-layer dimension<br>
    numHead = 8 # Numero head in cui suddividere input in multi-headed attention <br>
    N = 6 # numero layer uguali in encoder e decoder<br>
    len_src_vocab = len(IT.vocab)<br>
    len_trg_vocab = len(EN.vocab)<br>
    <br>
    model = Transformer(len_src_vocab, len_trg_vocab, dModel, N, numHead).to(device)<br>
    <br>
    for param in model.parameters():<br>
    <span style="margin-left:30px"> if param.dim() > 1:</span><br>
    <span style="margin-left:60px"> nn.init.xavier_uniform_(param)  </span><br>
    # Glorot initialization limitare parametri per non rendere troppo oneroso <br>
    <br>
    optim = torch.optim.Adam(model.parameters(), lr=0.005, betas=(0.9, 0.9998), eps=1e-9 )
    <br><br>
    model.train()<br>
    <br>
    total_loss = 0<br>
    check_iter = 100   <br> 
    lossModel =  nn.CrossEntropyLoss()<br>



</div>


<div class="model5">


for epoch in range(EPOCHS):<br>
       
<span style="margin-left:30px"> for i, train in enumerate(trainI): </span><br> 
 <span style="margin-left:60px"> source = train.IT.transpose(0,1)</span><br>
  <span style="margin-left:60px">  target = train.EN.transpose(0,1) </span><br>

 <span style="margin-left:60px"> # Nel target language si esclude ultima parola</span><br>
 <span style="margin-left:60px"> targetToDecoder = target[:, :-1]</span><br>
                
 <span style="margin-left:60px"> targets = target[:, 1:].contiguous().view(-1)</span><br>
  <span style="margin-left:60px"> targets = targets.to(device)</span><br>

<span style="margin-left:60px"> # crea mask per avere matrici con stesse dimensioni </span><br>
  <span style="margin-left:60px">  sourceMask, targetMask, targetPad  = creaMask(source, targetToDecoder )</span><br>
  <span style="margin-left:60px"> source.to(device)</span><br>
  <span style="margin-left:60px"> targetToDecoder.to(device)</span><br>
  <span style="margin-left:60px">  sourceMask.to(device)</span><br>
  <span style="margin-left:60px">  targetMask.to(device)</span><br>
       
<span style="margin-left:60px"> prediction = model(source, targetToDecoder , sourceMask, targetMask).to(device)</span><br>
       
 <span style="margin-left:60px"> optim.zero_grad()</span><br>
 <span style="margin-left:60px"> loss = lossModel(prediction.view(-1, prediction.size(-1)), targets)</span><br>
<span style="margin-left:60px"> loss.backward()</span><br>
 <span style="margin-left:60px"> torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)</span><br>
 <span style="margin-left:60px"> optim.step()</span><br>
        
  <span style="margin-left:60px">  total_loss += loss.item()</span><br>
 <span style="margin-left:60px">  if (i + 1) % check_iter  == 0:</span><br>
 <span style="margin-left:90px">  loss_avg = total_loss / check_iter </span><br>
<span style="margin-left:90px"> total_loss = 0</span><br>

</div>

<div class="model5">
    &lt;bound method Module.eval of Transformer(<br>
  (encoder): Encoder(<br>
    (embed): Embedding(<br>
      (embedding): Embedding(30669, 512)<br>
    )<br>
    (pe): PositionalEncoder()<br>
    (layers): ModuleList(<br>
      (0): EncoderLayer(<br>
        (norm1): Normalisation()<br>
        (norm2): Normalisation()<br>
        (mhattention): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
        (dropout1): Dropout(p=0.1, inplace=False)<br>
      )<br>
      (1): EncoderLayer(<br>
        (norm1): Normalisation()<br>
        (norm2): Normalisation()<br>
        (mhattention): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
        (dropout1): Dropout(p=0.1, inplace=False)<br>
      )<br>
      (2): EncoderLayer(<br>
        (norm1): Normalisation()<br>
        (norm2): Normalisation()<br>
        (mhattention): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
        (dropout1): Dropout(p=0.1, inplace=False)<br>
      )<br>
      (3): EncoderLayer(<br>
        (norm1): Normalisation()<br>
        (norm2): Normalisation()<br>
        (mhattention): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
        (dropout1): Dropout(p=0.1, inplace=False)<br>
      )<br>
      (4): EncoderLayer(<br>
        (norm1): Normalisation()<br>
        (norm2): Normalisation()<br>
        (mhattention): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
        (dropout1): Dropout(p=0.1, inplace=False)<br>
      )<br>
      (5): EncoderLayer(<br>
        (norm1): Normalisation()<br>
        (norm2): Normalisation()<br>
        (mhattention): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
        (dropout1): Dropout(p=0.1, inplace=False)<br>
      )<br>
    )<br>
    (norm): Normalisation()<br>
  )<br>
  (decoder): Decoder(<br>
    (embed): Embedding(<br>
      (embedding): Embedding(14938, 512)<br>
    )<br>
    (pe): PositionalEncoder()<br>
    (layers): ModuleList(<br>
      (0): DecoderLayer(<br>
        (norm_1): Normalisation()<br>
        (norm_2): Normalisation()<br>
        (norm_3): Normalisation()<br>
        (dropout_1): Dropout(p=0.1, inplace=False)<br>
        (dropout_2): Dropout(p=0.1, inplace=False)<br>
        (dropout_3): Dropout(p=0.1, inplace=False)<br>
        (attn_1): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (attn_2): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
      )<br>
      (1): DecoderLayer(<br>
        (norm_1): Normalisation()<br>
        (norm_2): Normalisation()<br>
        (norm_3): Normalisation()<br>
        (dropout_1): Dropout(p=0.1, inplace=False)<br>
        (dropout_2): Dropout(p=0.1, inplace=False)<br>
        (dropout_3): Dropout(p=0.1, inplace=False)<br>
        (attn_1): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (attn_2): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
      )<br>
      (2): DecoderLayer(<br>
        (norm_1): Normalisation()<br>
        (norm_2): Normalisation()<br>
        (norm_3): Normalisation()<br>
        (dropout_1): Dropout(p=0.1, inplace=False)<br>
        (dropout_2): Dropout(p=0.1, inplace=False)<br>
        (dropout_3): Dropout(p=0.1, inplace=False)<br>
        (attn_1): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (attn_2): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
      )<br>
      (3): DecoderLayer(<br>
        (norm_1): Normalisation()<br>
        (norm_2): Normalisation()<br>
        (norm_3): Normalisation()<br>
        (dropout_1): Dropout(p=0.1, inplace=False)<br>
        (dropout_2): Dropout(p=0.1, inplace=False)<br>
        (dropout_3): Dropout(p=0.1, inplace=False)<br>
        (attn_1): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (attn_2): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
      )<br>
      (4): DecoderLayer(<br>
        (norm_1): Normalisation()<br>
        (norm_2): Normalisation()<br>
        (norm_3): Normalisation()<br>
        (dropout_1): Dropout(p=0.1, inplace=False)<br>
        (dropout_2): Dropout(p=0.1, inplace=False)<br>
        (dropout_3): Dropout(p=0.1, inplace=False)<br>
        (attn_1): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (attn_2): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
      )<br>
      (5): DecoderLayer(<br>
        (norm_1): Normalisation()<br>
        (norm_2): Normalisation()<br>
        (norm_3): Normalisation()<br>
        (dropout_1): Dropout(p=0.1, inplace=False)<br>
        (dropout_2): Dropout(p=0.1, inplace=False)<br>
        (dropout_3): Dropout(p=0.1, inplace=False)<br>
        (attn_1): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (attn_2): MultiHeadAttention(<br>
          (q): Linear(in_features=512, out_features=512, bias=True)<br>
          (v): Linear(in_features=512, out_features=512, bias=True)<br>
          (k): Linear(in_features=512, out_features=512, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (output): Linear(in_features=512, out_features=512, bias=True)<br>
        )<br>
        (ff): FeedForward(<br>
          (linear1): Linear(in_features=512, out_features=2048, bias=True)<br>
          (dropout): Dropout(p=0.1, inplace=False)<br>
          (linear2): Linear(in_features=2048, out_features=512, bias=True)<br>
        )<br>
      )<br>
    )<br>
    (norm): Normalisation()<br>
  )<br>
  (out): Linear(in_features=512, out_features=14938, bias=True)<br>
)&gt;

</div>

<div class="model5">

    model.eval()<br>
    test_iter = BucketIterator(test, batch_size=32,device = device)<br>
    for i, test in enumerate(test_iter):  <br>
    <span style="margin-left:30px">  source = test.IT.transpose(0,1)</span><br>
    <br>
    sss = source[1]<br>
    
    src = torch.ones(max_sequence_length).type_as(sss.data)<br>
    src2 = [x for x in sss if x > 3  ]<br>
    <br>
    for i in range(len(src2)):<br>
    <span style="margin-left:30px">  src[i] = src2[i]</span><br>
       
    
    print(' '.join([IT.vocab.itos[i] for i in src if i > 3 ]  ))    <br>
    input_pad = IT.vocab.stoi[ "&lt;pad&gt;"]<br>
    src_mask = (src != input_pad).unsqueeze(-2)<br>
        
    encOut = model.encoder(src, sourceMask)<br>
    outputs = torch.zeros(max_sequence_length).type_as(src.data)<br>
    
    
    for i in range(1, max_sequence_length ):   <br> 
    <span style="margin-left:30px"> targetMask =  np.triu(np.ones((1, i, i)), k=1).astype('uint8')    </span><br>                                                         
    <span style="margin-left:30px"> targetMask = Variable(torch.from_numpy(targetMask) == 0).to(device)</span><br>

    <span style="margin-left:30px">  modelOut = model.out(model.decoder((outputs[:i].unsqueeze(0)), encOut, sourceMask, targetMask))    </span><br>
    <span style="margin-left:30px">  ris = F.softmax(out, dim=-1)</span><br>
    <span style="margin-left:30px">  _ , wordtoidx = ris[:, -1].data.topk(1)</span><br>
            
    <span style="margin-left:30px"> outputs[i] = wordtoidx[0][0]</span><br>
    <span style="margin-left:30px">  if wordtoidx[0][0] == 3 :</span><br>
    <span style="margin-left:60px">  break</span><br>
                
    ' '.join([EN.vocab.itos[i] for i in outputs[:i] if i > 3 ]    )<br>

</div>
<br> <br> <br> 
train GPU: <br> 
<br> 
epoch 5, iter = 8900, loss = 0.189 <br> 
epoch 5, iter = 9000, loss = 0.197 <br> 
epoch 5, iter = 9100, loss = 0.194<br> 
epoch 5, iter = 9200, loss = 0.196 <br> 
epoch 5, iter = 9300, loss = 0.209<br> 
epoch 5, iter = 9400, loss = 0.210 <br> 
epoch 5, iter = 9500, loss = 0.202 <br> 
epoch 5, iter = 9600, loss = 0.203 <br> 

<br> <br> <br> 
test <br> <br>

input : Era uno sciatore molto bravo quand' era piccolo .
<br> <br> <br> 

output : It was a very good skier when she was small . <br> 