
<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0" />
    <meta name="google-site-verification" content="VXixwtxrf--qUV1swfStEg9jOGPKgUm6C3Ub_vouqmc" />
    <title>MecBar | The Mec Evolution </title>
    <link rel="icon" href="foto/favicon.ico"/>
    <!-- CSS  -->
    <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection" />
    
    <script src="js/jquery-3.js"></script>
    
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
   
    <link href="https://fonts.googleapis.com/css?family=Raleway|Satisfy" rel="stylesheet">
    <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection" />

    <link href="css/style2.css" type="text/css" rel="stylesheet" media="screen,projection" />
    <link href="css/navbar.css" type="text/css" rel="stylesheet" media="screen,projection" />
 
</head>
<body>
<header>
    <nav>
        <li class="nav-wrapper back-home" id="head">
            <a href="http://www.mecbar.com/" class="brand-logo mecbar">
                <?xml version="1.0" encoding="UTF-8" standalone="no"?>
                <svg
                   xmlns:osb="http://www.openswatchbook.org/uri/2009/osb"
                   xmlns:dc="http://purl.org/dc/elements/1.1/"
                   xmlns:cc="http://creativecommons.org/ns#"
                   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                   xmlns:svg="http://www.w3.org/2000/svg"
                   xmlns="http://www.w3.org/2000/svg"
                   xmlns:xlink="http://www.w3.org/1999/xlink"
                   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
                   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
                   width="156"
                   height="64"
                   viewBox="0 0 12.3825 5.08"
                   version="1.1"
                   id="svg8"
                   inkscape:version="1.0 (6e3e5246a0, 2020-05-07)"
                   sodipodi:docname="mecbar.svg">
                  <defs
                     id="defs2">
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient2948">
                      <stop
                         id="stop2946"
                         offset="0"
                         style="stop-color:#c6126a;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient875">
                      <stop
                         id="stop873"
                         offset="0"
                         style="stop-color:#babd06;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3253"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#878734;stop-opacity:1;"
                         offset="0"
                         id="stop3251" />
                    </linearGradient>
                    <linearGradient
                       inkscape:collect="always"
                       id="linearGradient3093">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3089" />
                      <stop
                         style="stop-color:#c6126a;stop-opacity:0;"
                         offset="1"
                         id="stop3091" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3071"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3069" />
                    </linearGradient>
                    <rect
                       x="38.182308"
                       y="80.104469"
                       width="51.135052"
                       height="30.274338"
                       id="rect18630" />
                    <rect
                       x="160.31746"
                       y="77.487633"
                       width="134.35785"
                       height="60.829021"
                       id="rect18624" />
                    <rect
                       x="70.354279"
                       y="28.223705"
                       width="103.27115"
                       height="64.638908"
                       id="rect18618" />
                    <rect
                       x="32.55666"
                       y="25.199898"
                       width="5.2916665"
                       height="43.089287"
                       id="rect18612" />
                    <rect
                       x="34.029621"
                       y="65.792862"
                       width="93.441322"
                       height="26.673161"
                       id="rect18606" />
                    <rect
                       x="10.284417"
                       y="19.486744"
                       width="193.27823"
                       height="129.88597"
                       id="rect18596" />
                    <linearGradient
                       inkscape:collect="always"
                       xlink:href="#linearGradient3093"
                       id="linearGradient3101"
                       gradientUnits="userSpaceOnUse"
                       x1="3.1346149"
                       y1="23.792595"
                       x2="78.606865"
                       y2="23.792595" />
                    <filter
                       height="1"
                       y="-2.5183475e-16"
                       width="1"
                       x="-7.1910066e-17"
                       style="color-interpolation-filters:sRGB"
                       inkscape:label="Blend"
                       id="filter3198">
                      <feBlend
                         in2="SourceGraphic"
                         mode="multiply"
                         result="fbSourceGraphic"
                         id="feBlend3196" />
                      <feColorMatrix
                         result="fbSourceGraphicAlpha"
                         in="fbSourceGraphic"
                         values="0 0 0 -1 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0 1 0"
                         id="feColorMatrix3200" />
                      <feBlend
                         in2="fbSourceGraphic"
                         id="feBlend3202"
                         mode="multiply"
                         result="blend"
                         in="fbSourceGraphic" />
                      <feGaussianBlur
                         id="feGaussianBlur869"
                         stdDeviation="6.7542215e-15" />
                    </filter>
                    <linearGradient
                       gradientUnits="userSpaceOnUse"
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       id="linearGradient2950"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                    <linearGradient
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       gradientTransform="translate(2.3455617,-9.683066)"
                       gradientUnits="userSpaceOnUse"
                       id="linearGradient3064"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                  </defs>
                  <sodipodi:namedview
                     id="base"
                     pagecolor="#ffffff"
                     bordercolor="#666666"
                     borderopacity="1.0"
                     inkscape:pageopacity="0.0"
                     inkscape:pageshadow="2"
                     inkscape:zoom="0.7"
                     inkscape:cx="355.19772"
                     inkscape:cy="45.714286"
                     inkscape:document-units="mm"
                     inkscape:current-layer="layer1-6"
                     inkscape:document-rotation="0"
                     showgrid="false"
                     inkscape:window-width="1324"
                     inkscape:window-height="747"
                     inkscape:window-x="36"
                     inkscape:window-y="21"
                     inkscape:window-maximized="1"
                     units="px"
                     inkscape:snap-nodes="true"
                     inkscape:object-paths="true"
                     scale-x="0.3" />
                  <metadata
                     id="metadata5">
                    <rdf:RDF>
                      <cc:Work
                         rdf:about="">
                        <dc:format>image/svg+xml</dc:format>
                        <dc:type
                           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
                        <dc:title></dc:title>
                      </cc:Work>
                    </rdf:RDF>
                  </metadata>
                  <g
                     inkscape:label="Layer 1"
                     inkscape:groupmode="layer"
                     class="io"
                     id="layer1">
                    <rect
                       ry="7.1295023"
                       rx="10.726023"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="21.245117"
                       width="20.103241"
                       id="rect2824"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                    <g
                       inkscape:label="Layer 1"
                       id="layer1-6"
                       transform="matrix(0.16152221,0.0020121,0,0.13626925,0.08059628,0.86541284)"
                       style="mix-blend-mode:normal;fill:url(#linearGradient2950);fill-opacity:1;stroke-width:6.74038;filter:url(#filter3198);image-rendering:optimizeQuality">
                      <text
                         xml:space="preserve"
                         id="text18594"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18596);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;line-height:125%;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;letter-spacing:0px;word-spacing:0px;fill:url(#linearGradient3064);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
                         x="-4.0898471"
                         y="24.876211"
                         id="text18602"
                         transform="matrix(0.75566848,-0.20637119,0.34609071,1.2288151,0,0)"><tspan
                   sodipodi:role="line"
                   id="tspan18600"
                   x="-4.0898471"
                   y="24.876211"
                   style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:url(#linearGradient3064);fill-opacity:1;stroke-width:1.78339px">MecBar</tspan>        <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="0s;light_2.end"
                   dur="1s"
                   values="1;0"
                   attributeName="fill-opacity"
                   id="light_1" />       <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="light_1.end"
                   dur="1s"
                   values="0;1"
                   attributeName="fill-opacity"
                   id="light_2" />           </text>
                      <text
                         xml:space="preserve"
                         id="text18604"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18606);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18610"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18612);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18616"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18618);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18622"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18624);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18628"
                         style="font-style:normal;font-weight:normal;font-size:12.7px;line-height:125%;font-family:sans-serif;text-align:justify;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18630);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="0s;light_2.end"
                         dur="1s"
                         values="1;0"
                         attributeName="fill-opacity"
                         id="light_1" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="light_1.end"
                         dur="1s"
                         values="0;1"
                         attributeName="fill-opacity"
                         id="light_2" />
                    </g>
                    <rect
                       ry="7.1295042"
                       rx="10.726021"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="16.413473"
                       width="25.987757"
                       id="rect871"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                  </g>
                  <style
                     id="style43">
                           #tspan18600 {
                               
                              animation-name: mecOpacity;
                              animation-duration: 2s;
                              animation-iteration-count: infinite;
                              }
                              @keyframes mecOpacity {
                              0%   { fill-opacity:1 }
                                50%  {fill-opacity :0.1; }
                            100% { fill-opacity: 1; }
                              }
                    </style>
                </svg>
                </a>
            <a href="#" data-activates="mobile-demo" class="button-collapse"><i class="material-icons">menu</i></a>

            <ul class="right hide-on-med-and-down">
                <!--  <li> <a class="btn" onclick="Materialize.toast('Hello', 4000, 'Ciao' ,4000 )">Touch Me</a> </li>
              -->

              <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
              <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
                <li>
                    <a href=""> </a>
                </li>
                <li>
                    <a href=""> </a>
                </li>
            </ul>
          
              <ul class="side-nav" id="mobile-demo">
               <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
                 <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
            </ul>
        
            </li>
    </nav>
</header>
<script>
    MathJax = {
      loader: {load: ['input/asciimath', 'output/chtml']}
    }
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<body>
<div class="center titolo">
    <i>Tensorflow-Keras Neural Network</i>
 </div>

<div class="testo">
Tensorflow è un framework utile per costruire un Neural Network che ha due fondamentali componenti, i Tensor e la Computational Graph.
Il Tensor è una rappresentazione particolare di un array di n dimensiomi e la dimensione di un array 
viene indicata con il termine rank.<br>

Tensorflow ha diverse API in diversi livelli come si evince dallo schema sottostante :<br>
<div class="frame">
   <div class="BOX13">
  <span style="font-size:18px;text-align:left;color: blue;">HIGH LEVEL</span>
  <span style="font-size:14px;text-align:right"> Estimator  <br>    Keras    <br>     TF-Learn  <br>    TF-Slim </span><br><br>
   </div>
   <div class="BOX13">
      <span style="font-size:18px;text-align:left;color: rgb(98, 247, 39)">MID LEVEL</span>
      <span style="font-size:14px;text-align:right"> Layers  <br> Datasets <br> Metrics <br> Losses </span><br><br>
       </div>
       <div class="BOX13">
         <span style="font-size:18px;text-align:left;color: rgb(245, 19, 68)">LOW LEVEL</span>
         <span style="font-size:14px;text-align:right"> TF-Session  <br> TF-graph  </span><br><br>
          </div>

</div>




La differenza tra un tensor ed un array classico come ad esempio con numpy sono che un tensor 
può essere applicato sia alle GPU che alle TPU con maggiore velocità di calcolo, possono automaticamente calcolare i gradients e 
possono essere applicati anche su più elaboratori contemporaneamente.<br><br>
<div class="model">
tensor = tf.constant([[5, 25], [3, 7]])<br>
print(tensor)<br>
tf.Tensor([[ 5 25] [ 3  7]], shape=(2, 2), dtype=int32)<br>
matrice = tensor.numpy()<br>
print(matrice)<br>
[[ 5 25] [ 3  7]]<br>
</div>
 <br>

 La Computational Graph è un metodo che rappresenta un processo in steps, un data flow graph in 
 cui si inseriscono le singole operazioni.<br><br>

I Low level sono tf.Session e tf.Graph.  <br>
I Mid Level sono tf.layer per i Layer, tf.Data per i Datasets, tf.metrics per i Metrics e tf.losses per i Loss packages. 
<br>
I Layers packages ci forniscono tutta una serie di strumenti per costruire i Neural Network e successivamente 
ne vedremo alcuni esempi.  <br>
I Datasets packages forniscono degli strumenti per acquisire e preparare i files in input per i 
NN. <br>

Per High level abbiamo strumenti che ci permettono di creare NN in modo astratto senza dover gestire tutti i componenti 
necessari.   <br>

Negli Estimator esistono diversi modelli già pronti da utilizzare per la Linear Regression, Random Forest Deep Neural Network sia per 
regression che classification. Un esempio è tf.compat.v1.estimator.DNNClassifier in cui inserendo i dati e altri parametri si 
ottiene un modello di classificazione. <br>

<span class="titoloGo"><b>Keras </b> </span><br>
è una high level API di tensorflow per creare modelli di NN con tutti i componenti. <br>
<b>Sequential model</b> è una modalità di creare un modello aggiungendo i layer dove ognuno ha un input ed un output come 
nell'esempio seguente:<br>

<div class="model">
from tensorflow.keras.models import Sequential<br>
from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D<br>
# Creazione  Sequential Model con layers<br>
model = Sequential()<br>
model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))<br>
model.add(MaxPooling2D(pool_size=(2, 2)))<br>
model.add(Flatten()) # Flattening the 2D arrays for fully connected layers<br>
model.add(Dense(128, activation=tf.nn.relu))<br>
model.add(Dropout(0.2))<br>
#model.add(linear)<br>
model.add(Dense(10,activation=tf.nn.softmax))<br>
<br>
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])<br>
model.fit(x=x_train,y=y_train, epochs=2)<br>
<br>

# estrarre i dati di input o di output nei diversi layer<br>
estrattore = Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers])<br>
dati = estrattore(x_train)  <br>
dati <br>
tf.Tensor: shape=(60000, 10), dtype=float32, numpy=
array([[2.8488181e-10, 5.4973871e-08, 1.5923844e-08, ..., 4.6386925e-09,
        1.6970350e-08, 6.8226524e-07], .... 5.9996935e-04]], dtype=float32)<br><br>
</div>

<span class="titoloGo"><b>Keras functional API</b></span> è un'altra modalità utile per creare modelli in modo flessibile per 
inserire layer con diversi input o output.<br>
<br>
<div class="model">
from tensorflow.keras.models import Model<br>
from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input<br>
<br>   
inputs = Input(input_shape)<br>
l1 = Conv2D(28, kernel_size=(3,3)) (inputs)<br>
l2 = MaxPooling2D(pool_size=(2, 2)) (l1)<br>
l3 = Flatten() (l2)<br>
l4 = Dense(128, activation=tf.nn.relu) (l3)<br>
l5 = Dropout(0.2) (l4)<br>
l6 = Dense(64, activation=tf.nn.relu) (l5)<br>
output = Dense(10,activation='softmax')(l6)<br>
model = Model(inputs=inputs, outputs=output)<br>
<br>
model.compile(optimizer='adam', <br>
              loss='sparse_categorical_crossentropy', <br>
              metrics=['accuracy'])<br>
model.fit(x=x_train,y=y_train, epochs=2)<br>
<br>
model.evaluate(x_test, y_test)<br>
</div>
<br><span class="titoloGo">
OPERAZIONI COMUNI DA ESEGUIRE CON I MODELLI </span> <br> 
model.summary() # per avere i dati del modello     <br>
keras.utils.plot_model(model, show_shapes=True) # per avere il grafico del modello  <br>
model.save("path/nome_modello") # save modello  <br>
del model # delete del modello dalla memoria <br>
model = keras.models.load_model("path/nome_modello") # load modello salvato precedentemente  <br>
<br>

<span class="titoloGo"><b>CUSTOM MODEL </b> </span> <br> <br>
Con Keras possiamo costruirci dei modelli in base alle nostre necessità inserendo i layer forniti da Tensorflow o costruendono 
dei propri e utilizzanto gli optimizer, loss, metrics e le altre utilities.<br>
Vediamo un esempio di un modello di CNN come i precedenti ma creato in modo custom inserendo un ciclo per esegure le 
diverse epoch senza utilizzare i metofi compile e fit.
In questo modello inseriamo anche un altra utility, kerastuner, per scegliere gli hyperparameter in modo 
automatico  <br><br>

<div class="model">
import tensorflow as tf<br>
from tensorflow import keras<br>
import numpy as np<br>
import kerastuner as kt<br>
from tensorflow.keras.layers import Dense, Flatten, Conv2D,MaxPooling2D,Dropout<br>
from tensorflow.keras import Model<br>
<br>
hp = kt.HyperParameters()<br>
<br>
EPOCHS = 10<br>
BATCH_SIZE= 32<br>
# questa utility raggruppa in modo randum in gruppi in base a bacth_size <br>
train = <span class="pyc2"> tf.data.Dataset.from_tensor_slices</span>((x_train, y_train)).shuffle(10000).batch(BATCH_SIZE)<br>

test =<span class="pyc2"> tf.data.Dataset.from_tensor_slices</span>((x_test, y_test)).batch(BATCH_SIZE)<br>
test  <br>
BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.uint8)<br>
<br>
<span class="pyc"> class</span> Qcnn(Model):<br>
<span style="margin-left:30px"> <span class="pyc">  def</span> __init__(self):</span><br>
  <span style="margin-left:60px"> super(Qcnn, self).__init__()</span><br>
    <span style="margin-left:60px"> self.l1 = Conv2D(filters=hp.Int('units', min_value=32, max_value=512, step=32) ,kernel_size=(3,3), activation='relu')</span><br>
    <span style="margin-left:60px"> #self.l1 = Conv2D(28, kernel_size=(3,3), activation='relu')</span><br>
    <span style="margin-left:60px"> self.l2 = MaxPooling2D(pool_size=(2, 2)) </span><br>
    <span style="margin-left:60px"> self.l3 = Flatten() </span><br>
    <span style="margin-left:60px">  self.l4 = Dense(256, activation=tf.nn.relu) </span><br>
    <span style="margin-left:60px"> self.l5 = Dropout(0.2)    </span><br>
 <span style="margin-left:60px">   self.l6 = Dense(10, activation='softmax') </span><br>


 <span style="margin-left:30px"> <span class="pyc">  def</span> call(self, x):</span><br>
  <span style="margin-left:60px">     x = self.l1(x)</span><br>
  <span style="margin-left:60px">    x = self.l2(x) </span><br>
  <span style="margin-left:60px">    x = self.l3(x) </span><br>
  <span style="margin-left:60px">    x = self.l4(x) </span><br>
  <span style="margin-left:60px">    x = self.l5(x) </span><br>
  <span style="margin-left:60px">     return self.l6(x) </span><br>
  <br><br>

model = Qcnn():<br><br>
trainLoss = <span class="pyc2"> tf.keras.metrics.Mean</span>(name='trainLoss')<br>
trainAccuracy =<span class="pyc2">  tf.keras.metrics.SparseCategoricalAccuracy</span>(name='trainAccuracy')<br>
testLoss =<span class="pyc2"> tf.keras.metrics.Mean</span>(name='testLoss'):<br>
testAccuracy = <span class="pyc2">tf.keras.metrics.SparseCategoricalAccuracy</span>(name='testAccuracy')<br>
lossF =<span class="pyc2">  tf.keras.losses.SparseCategoricalCrossentropy</span>(from_logits=False):<br>
optimizer = <span class="pyc2"> tf.keras.optimizers.Adam(hp.Choice</span>('learning_rate', values=[1e-2, 1e-3, 1e-4]))<br>
<br>
<span class="pyc"> @tf.function</span>   #attiva tensorflow graf<br>
<span class="pyc"> def</span> trainModel(x, y):<br>

<span style="margin-left:30px"> <span class="pyc"> with</span><span class="pyc2"> tf.GradientTape()</span> as gra:</span><br>
<span style="margin-left:60px">   # training=True Dropout</span><br>
 <span style="margin-left:60px">    y_pred = model(x, training=True)</span><br>
<span style="margin-left:60px">     loss = lossF(y, y_pred)</span><br>
 <span style="margin-left:30px">  gradients =<span class="pyc2">  gra.gradient</span>(loss, model.trainable_variables)</span><br>
 <span style="margin-left:30px">  optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br>

 <span style="margin-left:30px">  trainLoss(loss)</span><br>
 <span style="margin-left:30px">  trainAccuracy(y, y_pred)</span><br>
 <br>

 <span class="pyc"> @tf.function</span><br>
 <span class="pyc"> def </span>  testModel(x, y):<br>
<span style="margin-left:30px">   # training=False se Dropout</span><br>
<span style="margin-left:30px">   y_pred = model(x, training=False)</span><br>
<span style="margin-left:30px">   loss = lossF(y, y_pred)</span><br>

 <span style="margin-left:30px">   testLoss(loss)</span><br>
<span style="margin-left:30px">   testAccuracy(y, y_pred)</span><br>
<br>

for epoch in range(EPOCHS)::<br>
<span style="margin-left:30px">  # il metodo reset_states azzera i contatori ad ogni epoch</span><br>
 <span style="margin-left:30px">    trainLoss.reset_states()</span><br>
  <span style="margin-left:30px">   trainLoss.reset_states()</span><br>
 <span style="margin-left:30px">  trainAccuracy.reset_states()</span><br>
  <span style="margin-left:30px">  testLoss.reset_states()</span><br>
 <span style="margin-left:30px">  testAccuracy.reset_states()</span><br>

 <span style="margin-left:30px">  for x, y in train:</span> # passa un blocco(batch_size) alla volta<br>
 <span style="margin-left:60px">     x = <span class="pyc2"> tf.constant</span>(x)</span><br>
 <span style="margin-left:60px">      y = <span class="pyc2"> tf.constant</span>(y)</span><br>
 <span style="margin-left:60px">     trainModel(x, y)</span><br>

 <span style="margin-left:30px">    for x, y in test:</span><br>
 <span style="margin-left:60px">    testModel(x, y)</span><br>

<span style="margin-left:30px">  print(f'Epoch {epoch + 1}, ' f'Train Loss: {trainLoss.result():3.2f}, '   f'Train Accuracy: {trainAccuracy.result() * 100 :3.2f}, '
       f'Test Loss: {testLoss.result() :3.2f}, '    f'Test Accuracy: {testAccuracy.result() * 100 :3.2f} '    )</span><br>

<br>
    Epoch 20, Train Loss: 0.07, Train Accuracy: 99.41, Test Loss: 0.53, Test Accuracy: 98.39 
</div>

 <br><br><br>
Vediamo ora come creare dei custom LAYER  per ottenere la 
funzione <span class="pyc2"> y = w*x + b </span> w sono i weights e b sono i bias per inserendo x in input 
il layer restituisce y in output che poi sarà l'input per il layer successivo. <br> I valori di w vengono 
inizializzati con numeri random mentre b con tutti zero.
<br> <br>

<div class="model">
    <span class="pyc">class</span> myLayer(layers.Layer): <br>

<span style="margin-left:30px"><span class="pyc"> def</span> __init__(self, batch_size=64, units=10,**kwargs):</span><br>
 <span style="margin-left:60px">     super(myLayer(, self).__init__()</span><br>
 <span style="margin-left:60px">    w_init = tf.random_normal_initializer()</span><br>
   <span style="margin-left:60px">     self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units),</span><br>
  <span style="margin-left:120px">                                            dtype='float32'),</span><br>
 <span style="margin-left:120px">                                          trainable=True)</span><br>
   <span style="margin-left:60px">     b_init = tf.zeros_initializer()</span><br>
 <span style="margin-left:60px">     self.b = tf.Variable(initial_value=b_init(shape=(units,),</span><br>
  <span style="margin-left:120px">    dtype='float32'),</span><br>
  <span style="margin-left:30px"> <span class="pyc"> def</span> call(self, inputs):</span><br>
    
    <span style="margin-left:60px">  return tf.matmul(inputs, self.w) + self.b</span><br>
       
    <br> <br>
myLay = myLayer() <br> <br>

ilayer = myLay(inp) <br>
ilayer2 = myLay(ilayer) <br>
...   <br>
</div>

<span class="titoloGo"><b>Gradient</b> </span><br> <br>

I gradient si usano per effettuare la backpropagation per ottenere la migliore y = w*x + con il modello 
che si vuole creare. è una tecnica per valutare la derivate di una funzione nella computaniotal graph.  <br>

Tensorflow ci fornisce una funzione che utilizzata con il comando with di python ci permette di 
effettuare i calcoli in modo automatico in un context manager e decidere quali variabili(tensor) possono essere visti ed elaborati 
dal gradient.  <br>

<div class="model">
    x = tf.Variable([3.0, 2.0, 5.0])<br>
    a = tf.Variable([1.0,2.0])<br><br>
    with <span class="pyc">tf.GradientTape(persistent=True,watch_accessed_variables=False )</span> as tape:<br>
    <span style="margin-left:30px"> <span class="pyc">tape.watch(x)</span></span><br>
     <span style="margin-left:30px"> y = x * x</span><br>
     <span style="margin-left:30px">  z = y * y</span><br>
     <span style="margin-left:30px">   print('x = ', x)</span><br>
    <span style="margin-left:30px">   print('y = ', y)</span><br>
     <span style="margin-left:30px">   z = y * y</span><br>
    <span style="margin-left:30px">   q = a * a</span><br>
     <span style="margin-left:30px">   print('z = ', z)</span><br>
     <span style="margin-left:30px">   print('q = ', q)</span><br>
     <br>
     derdzdx = <span class="pyc">tape.gradient(z, x)</span> # target e source in input # si calcola (4*x^3 at x = ?)<br>
     derdydx = <span class="pyc">tape.gradient(y, x)</span>  # target e source in input # si calcola x*2 at x = ?)<br>
     derdqdx = <span class="pyc">tape.gradient(q, x)</span> 
     <br><br>
    print(`dz/dx` =  derdzdx)<br><br>
    print(`dy/dx` =  derdydx)<br><br>
    print(`(dq)/dx` =  derdqdx)<br><br>
    <br>
    RISULTATI:<br>
    x =  tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([3., 2., 5.], dtype=float32) <br>
    <span class="pyc2"> y </span>=  tf.Tensor([ 9.  4. 25.], shape=(3,), dtype=float32)<br>
    <span class="pyc2"> z</span> =  tf.Tensor([ 81.  16. 625.], shape=(3,), dtype=float32)<br>
    <span class="pyc2">q</span>   =  tf.Tensor([1. 0.], shape=(2,), dtype=float32)<br>
    <span class="pyc2">   `dz/dx`  </span>=  tf.Tensor([108.  32. 500.], shape=(3,), dtype=float32)<br><br>
    <span class="pyc2">   `dy/dx`</span> =  tf.Tensor([ 6.  4. 10.], shape=(3,), dtype=float32)<br><br>
    <span class="pyc2">  `(dq)/dx`</span> =  None<br><br>

</div>
Sopra nell'esempio inserito possiamo notare le peculiarità di questa funzione che con i parametri inseriti 
(persistent=True) mantiene copia dei calcoli effettuati e (watch_accessed_variables=False) non accede prende in considerazione le 
variabile se non espressamente previsto con il metodo watch() per il calcolo dei gradients come possiamo notare dal valore della 
variabile `(dq)/dx` che dopo il calcolo del gradient il suo valore è uguale a None.<br>



<br><br><br><br>
<span class="titoloGo">
<b>TensorBoard</b>  </span><br><br>è una intefaccia grafica interattiva che permette di vedere la creazione ed esecuzione della 
Computational graph.  <br><br>
<span class="titoloGo">
<b>TensorFlow's eager execution</b> </span> <br>
è un programming environment dove le operazioni vengono valutate subito senza costruire la computational graph
ritornando subito il risultato e successivamente verrà creato il graph.
Questa modalità è operativa di default ma può essere disattivata con il comando tf.compat.v1.disable_eager_execution()
ad esempio per eseguire operazioni all'interno della session. 
Per vedere lo stato il comando tf.executing_eagerly() return True se attiva. <br><br>

<span class="titoloGo"><b>TensorFlow's Graphs</b></span> <br>
dati strutturati con dei set di oggetti di operazioni tf.Operation e tf.Tensor(dati) visualizzabili 
tramite Tensordoard in grafici dove visualizzare il tracciato logico delle operazioni eseguite sui dati inseriti.  
Questi dati possono essere salvati e rieseguiti senza il codice python originale ad esmpio su smartphone ... o backend server.
<br><br>
<span class="titoloGo"><b>@tf.function</b> </span> <br>
questa property attiva nella funzione a cui viene applicata la tensorflow graf cioè alla funzione 
si crea una computational graph accelerando l'esecuzione. <br>
I dati inseriti in input alla funzione devono essere passati con con tf.Constant o tf.Variable.<br><br> 



Vediamo alcuni comandi che si usano nei tensor: <br><br>
<div class="model">
    <span class="pyc2"> tf.constant()</span> - per creare costanti <br>
    <span class="pyc2"> tf.placeholder()</span> - per il passaggio dei dati nella computational graph  <br>
    <span class="pyc2"> tf.variable()</span> - per inserire dati che poi verranno modificati successivamente   <br>
<br><br>
t1 = tf.constant(8)<br>
t2 = tf.constant(4)
<br><br>
tf.Tensor(8, shape=(), dtype=int32)<br>
tf.Tensor(4, shape=(), dtype=int32)
<br><br>
uno = <span class="pyc2"> tf.divide(t1,t2)</span><br>
due = <span class="pyc2"> tf.subtract(t1,t2)</span><br>
tre = <span class="pyc2"> tf.multiply(t1,t2)</span><br>
quattro =<span class="pyc2">  tf.add(t1,t2)</span>

<br><br>
with <span class="pyc2"> tf.compat.v1.Session()</span> as sess:<br>
     r1 = uno.numpy()<br>
     r2 = due.numpy()<br>
     r3 = tre.numpy()<br>
     r4 = quattro.numpy()<br>
     result = [r1, r2,r3,r4]<br>
     
     <br><br>

tenres =<span class="pyc2">  tf.convert_to_tensor(result)</span><br>
print(tenres)
<br><br>
tf.Tensor([ 2.  4. 32. 12.], shape=(4,), dtype=float64)
<br><br>




(x_train, y_train), (x_test, y_test) = <span class="pyc2"> tf.keras.datasets.mnist.load_data()</span> #load mnist dataset <br>
x_train, x_test = x_train / 255.0, x_test / 255.0  #normalizzazione - riduzione valore numeri <br>
<br>
# Add a channels dimension - 1 nuova dimensione <br>
x_train = x_train[..., tf.newaxis].astype("float32")<br>
x_test = x_test[..., tf.newaxis].astype("float32")<br>
# shuffle e prepare the dataset in bach <br>
train = <span class="py2"> tf.data.Dataset.from_tensor_slices</span>(<br>
    (x_train, y_train)).shuffle(10000).batch(64)<br>
    <br>
test = <span class="pyc2"> tf.data.Dataset.from_tensor_slices</span>((x_test, y_test)).batch(32)<br>
</div>





<span class="titoloGo">ESEMPIO PLACEHOLDER </span>  <br>
<br>
<div class="model">
with <span class="pyc2"> tf.compat.v1.Session()</span> as sess:<br>
<span class="pyc2"> tf.compat.v1.disable_eager_execution()</span> #disable eager<br>
  a = <span class="pyc2"> tf.compat.v1.placeholder</span>(dtype=tf.float32, shape=None)<br>
  b =<span class="pyc2">  tf.compat.v1.placeholder</span>(dtype=tf.float32, shape=None)<br>
  <br>
  c =<span class="pyc2"> tf.sqrt(tf.pow(a,2) + tf.pow(b,2)) </span>  #pow = a^2  + b^2 = radice quadrata c^2<br>
  risultato = sess.run(c, feed_dict={a: 2, b: 5})  # feed_dict inserisce dati nel placeholder<br>
  print(risultato)<br><br>

risultato = 5.3851647<br>
</div>
<br><br>
<span class="titoloGo">
ESEMPIO EVAL() PER VEDERE VALORE COSTANTI/VARIABILI</span> <br><br>
<div class="model">
 <span class="pyc2"> tf.compat.v1.reset_default_graph()</span><br>
a = <span class="rosso"> tf.constant(10)</span><br>
b = <span class="rosso"> tf.constant(5)</span><br>
c = <span class="rosso"> tf.add(a,b)</span><br>
print(c)  <br>
<br>
Tensor("mul:0", shape=(), dtype=int32)<br><br>

with<span class="blu">  tf.compat.v1.Session()</span> as sess:<br>
   print(c.eval())<br>
   <br>
50<br>
</div>

<br><br>


<span class="titoloGo">VARIABLE : </span>  <br>
una peculiarità è che i dati inseriti nelle variabili possono essere visti e modificati 
<br>in processi appartenenti a diverse sessioni. <br>
- creare tf.Variable() o tf.get_variable() <br>
- assegnare un nuovo valore tf.asssign() <br>
- <span class="verde"> tf.compat.v1.assign_add() </span>- aggiungere dati<br>
-  <span class="rosso">tf.compat.v1.assign_sub() </span>- sottrarre dati <br>
prima di manipolare una variabile in una session deve essere inizializzata con i comandi tf.compat.v1.global_variables_initializer()<br>
per tutte le variabili o applicando il metodo .initialized(). <br><br>


<div class="model">
v1 =<span class="pyc2">  tf.Variable(2, dtype=tf.float32)</span><br>
v2 = <span class="pyc2"> tf.Variable(3, dtype=tf.float32)</span><br>
<span class="pyc2"> tf.compat.v1.global_variables_initializer()</span><br>
<br>
v3 = <span class="pyc2"> tf.compat.v1.assign_add(v1, v2)</span><br>
<span class="pyc2"> tf.compat.v1.assign_sub(v3, v2)  </span> # sottrae v2 da v3 ed aggiorna il valore di v3  <br><br>
</div>
<span class="titoloGo">
<b>Variable scope</b> </span> <br>impedisce di usare variabili con lo stesso nome e per rieseguire 
comandi prima bisogna eseguire il comando <span class="pyc2"> tf.compat.v1.reset_default_graph()</span> <br><br>

<div class="model">
    <span class="pyc2"> tf.compat.v1.variable_scope</span><br>
    <span class="pyc"> def</span> fx(a, b):<br>
     a = <span class="pyc2"> tf.compat.v1.get_variable(name = "a", initializer = tf.constant(a, dtype=tf.float32))</span><br>
     b =<span class="pyc2">  tf.compat.v1.get_variable(name = "b", initializer = tf.constant(b, dtype=tf.float32))</span><br>
     return<span class="pyc2">  tf.add(a,b)</span><br>
     <br>
with <span class="pyc2"> tf.compat.v1.variable_scope("x1")</span><br>
     c = fx(3, 4)<br>
     print(c)<br>
     <br>
with <span class="pyc2"> tf.compat.v1.variable_scope("x2")</span><br>
     c = fx(3, 4) - 5<br>
     print(c)<br>
     <br>
     tf.Tensor(7.0, shape=(), dtype=float32)<br>
     tf.Tensor(2.0, shape=(), dtype=float32)<br>
     <br>
</div>
I weights di un neural network vengono inseriti in variabili con un valore iniziale <br>
<div class="model">
iv = <span class="pyc2"> tf.random.normal(shape=(2, 2))</span><br>
a = <span class="pyc2"> tf.Variable(iv)</span><br>
print(a)<br><br>
tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=
array([[ 0.22797322, -0.35832703],
       [ 0.24170108,  0.86340433]], dtype=float32)<br><br>
</div>


<span class="titoloGo">ALTRI COMANDI </span> <br><br>

<span class="pyc2"> tf.one_hot</span> per OneHotEncoder - convertire in numeri valori alfanumerici <br>

with <span class="pyc2"> tf.device('/gpu:0')</span> per selezionare gpu/cpu/tpu e/o numero device <br>








<span class="titoloGo">

Gradients   </span> <br><br>

Tensor automaticamente fa retrieve dei gradients di alcune differentiable expression.
<br>

with tf.GradientTape() as tape:<br>
    tape.watch(x)  <br>
    <br>

per vedere contenuto del gradient.<br>

<span class="titoloGo">
LAYER </span> <br>
A Layer encapsulates a state (weights) and some computation (defined in the call method).<br>

definiamo a layer e lo istanziamo <br>


<span class="verde">model.summary()</span><br>
<span class="blu"> model.save()</span><br>
<span class="rosso">  history = model.fit()</span><br>
  history.history()<br>

  Using callbacks for checkpointing.  save model.<br>
  
  <br>

  <span class="titoloGo">
Padding </span><br>
inputs = <span class="verde">tf.keras.preprocessing.sequence.pad_sequences(<br>
    input, padding="post"</span> <br>
)<br>
<br>
<span class="titoloGo">
Masking </span> <br> - parti riempite da padding non considerate <br>
<br>
1 Add a keras.layers.Masking layer or  configure a keras.layers.Embedding layer with mask_zero=True.
<br>
2 embedding = <span class="verde">layers.Embedding(input_dim=100, output_dim=30, mask_zero=True)</span><br>
masked = embedding(inputs)<br>
<br>
print(masked._keras_mask)<br>
<br>
3 Passing mask tensors directly to layers custom <br>
<br>

a = model.layers[5]<br>
a.output<br>
a.variables<br>
b = a.kernel<br>
c = b.numpy()<br>
c.shape<br>
c.argmax()<br>
a.weights    contiene kernel e bias <br> 

<br>
<div class="model">
from tensorflow.keras import layers<br>
<br>

class Linear(layers.Layer):<br>
<br>
<span style="margin-left:30px">   def __init__(self, units=32, input_dim=32):<br></span>
 <span style="margin-left:30px">     super(Linear, self).__init__()<br></span>
 <br>
 <span style="margin-left:30px">   def call(self, inputs):<br></span>
 <span style="margin-left:60px">     print("execute executing_eagerly =", tf.executing_eagerly())<br></span>
 <span style="margin-left:60px">     print(1, inputs)<br></span>
<span style="margin-left:60px">     a = inputs.numpy()  # ok <br></span>
 <span style="margin-left:60px">     print(a, inputs.shape, 20)<br></span>
 <br>
<span style="margin-left:60px">     return </span><br><br>

</div>


se input :<br>
x = tf.ones((1, 2)  #ok<br>
<br>
se x_train  numpy non ok  tf.executing_eagerly() = false<br>



</div>

</body>


</html>
