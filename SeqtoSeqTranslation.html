
<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0" />
    <meta name="google-site-verification" content="VXixwtxrf--qUV1swfStEg9jOGPKgUm6C3Ub_vouqmc" />
    <title>MecBar | The Mec Evolution </title>
    <link rel="icon" href="foto/favicon.ico"/>
    <!-- CSS  -->
    <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection" />
    
    <script src="js/jquery-3.js"></script>
    
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
   
    <link href="https://fonts.googleapis.com/css?family=Raleway|Satisfy" rel="stylesheet">
    <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection" />

    <link href="css/style2.css" type="text/css" rel="stylesheet" media="screen,projection" />
    <link href="css/navbar.css" type="text/css" rel="stylesheet" media="screen,projection" />
 
</head>
<header>
    <nav>
        <li class="nav-wrapper back-home" id="head">
            <a href="http://www.mecbar.com/" class="brand-logo mecbar">
                <?xml version="1.0" encoding="UTF-8" standalone="no"?>
                <svg
                   xmlns:osb="http://www.openswatchbook.org/uri/2009/osb"
                   xmlns:dc="http://purl.org/dc/elements/1.1/"
                   xmlns:cc="http://creativecommons.org/ns#"
                   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                   xmlns:svg="http://www.w3.org/2000/svg"
                   xmlns="http://www.w3.org/2000/svg"
                   xmlns:xlink="http://www.w3.org/1999/xlink"
                   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
                   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
                   width="156"
                   height="64"
                   viewBox="0 0 12.3825 5.08"
                   version="1.1"
                   id="svg8"
                   inkscape:version="1.0 (6e3e5246a0, 2020-05-07)"
                   sodipodi:docname="mecbar.svg">
                  <defs
                     id="defs2">
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient2948">
                      <stop
                         id="stop2946"
                         offset="0"
                         style="stop-color:#c6126a;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       osb:paint="solid"
                       id="linearGradient875">
                      <stop
                         id="stop873"
                         offset="0"
                         style="stop-color:#babd06;stop-opacity:1;" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3253"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#878734;stop-opacity:1;"
                         offset="0"
                         id="stop3251" />
                    </linearGradient>
                    <linearGradient
                       inkscape:collect="always"
                       id="linearGradient3093">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3089" />
                      <stop
                         style="stop-color:#c6126a;stop-opacity:0;"
                         offset="1"
                         id="stop3091" />
                    </linearGradient>
                    <linearGradient
                       id="linearGradient3071"
                       osb:paint="solid">
                      <stop
                         style="stop-color:#c6126a;stop-opacity:1;"
                         offset="0"
                         id="stop3069" />
                    </linearGradient>
                    <rect
                       x="38.182308"
                       y="80.104469"
                       width="51.135052"
                       height="30.274338"
                       id="rect18630" />
                    <rect
                       x="160.31746"
                       y="77.487633"
                       width="134.35785"
                       height="60.829021"
                       id="rect18624" />
                    <rect
                       x="70.354279"
                       y="28.223705"
                       width="103.27115"
                       height="64.638908"
                       id="rect18618" />
                    <rect
                       x="32.55666"
                       y="25.199898"
                       width="5.2916665"
                       height="43.089287"
                       id="rect18612" />
                    <rect
                       x="34.029621"
                       y="65.792862"
                       width="93.441322"
                       height="26.673161"
                       id="rect18606" />
                    <rect
                       x="10.284417"
                       y="19.486744"
                       width="193.27823"
                       height="129.88597"
                       id="rect18596" />
                    <linearGradient
                       inkscape:collect="always"
                       xlink:href="#linearGradient3093"
                       id="linearGradient3101"
                       gradientUnits="userSpaceOnUse"
                       x1="3.1346149"
                       y1="23.792595"
                       x2="78.606865"
                       y2="23.792595" />
                    <filter
                       height="1"
                       y="-2.5183475e-16"
                       width="1"
                       x="-7.1910066e-17"
                       style="color-interpolation-filters:sRGB"
                       inkscape:label="Blend"
                       id="filter3198">
                      <feBlend
                         in2="SourceGraphic"
                         mode="multiply"
                         result="fbSourceGraphic"
                         id="feBlend3196" />
                      <feColorMatrix
                         result="fbSourceGraphicAlpha"
                         in="fbSourceGraphic"
                         values="0 0 0 -1 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0 1 0"
                         id="feColorMatrix3200" />
                      <feBlend
                         in2="fbSourceGraphic"
                         id="feBlend3202"
                         mode="multiply"
                         result="blend"
                         in="fbSourceGraphic" />
                      <feGaussianBlur
                         id="feGaussianBlur869"
                         stdDeviation="6.7542215e-15" />
                    </filter>
                    <linearGradient
                       gradientUnits="userSpaceOnUse"
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       id="linearGradient2950"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                    <linearGradient
                       y2="9.1505461"
                       x2="228.5569"
                       y1="9.1505461"
                       x1="3.1346149"
                       gradientTransform="translate(2.3455617,-9.683066)"
                       gradientUnits="userSpaceOnUse"
                       id="linearGradient3064"
                       xlink:href="#linearGradient2948"
                       inkscape:collect="always" />
                  </defs>
                  <sodipodi:namedview
                     id="base"
                     pagecolor="#ffffff"
                     bordercolor="#666666"
                     borderopacity="1.0"
                     inkscape:pageopacity="0.0"
                     inkscape:pageshadow="2"
                     inkscape:zoom="0.7"
                     inkscape:cx="355.19772"
                     inkscape:cy="45.714286"
                     inkscape:document-units="mm"
                     inkscape:current-layer="layer1-6"
                     inkscape:document-rotation="0"
                     showgrid="false"
                     inkscape:window-width="1324"
                     inkscape:window-height="747"
                     inkscape:window-x="36"
                     inkscape:window-y="21"
                     inkscape:window-maximized="1"
                     units="px"
                     inkscape:snap-nodes="true"
                     inkscape:object-paths="true"
                     scale-x="0.3" />
                  <metadata
                     id="metadata5">
                    <rdf:RDF>
                      <cc:Work
                         rdf:about="">
                        <dc:format>image/svg+xml</dc:format>
                        <dc:type
                           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
                        <dc:title></dc:title>
                      </cc:Work>
                    </rdf:RDF>
                  </metadata>
                  <g
                     inkscape:label="Layer 1"
                     inkscape:groupmode="layer"
                     class="io"
                     id="layer1">
                    <rect
                       ry="7.1295023"
                       rx="10.726023"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="21.245117"
                       width="20.103241"
                       id="rect2824"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                    <g
                       inkscape:label="Layer 1"
                       id="layer1-6"
                       transform="matrix(0.16152221,0.0020121,0,0.13626925,0.08059628,0.86541284)"
                       style="mix-blend-mode:normal;fill:url(#linearGradient2950);fill-opacity:1;stroke-width:6.74038;filter:url(#filter3198);image-rendering:optimizeQuality">
                      <text
                         xml:space="preserve"
                         id="text18594"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18596);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;line-height:125%;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;letter-spacing:0px;word-spacing:0px;fill:url(#linearGradient3064);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
                         x="-4.0898471"
                         y="24.876211"
                         id="text18602"
                         transform="matrix(0.75566848,-0.20637119,0.34609071,1.2288151,0,0)"><tspan
                   sodipodi:role="line"
                   id="tspan18600"
                   x="-4.0898471"
                   y="24.876211"
                   style="font-style:oblique;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:25.0978px;font-family:Purisa;-inkscape-font-specification:'Purisa, Oblique';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:url(#linearGradient3064);fill-opacity:1;stroke-width:1.78339px">MecBar</tspan>        <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="0s;light_2.end"
                   dur="1s"
                   values="1;0"
                   attributeName="fill-opacity"
                   id="light_1" />       <animate
                   style="fill-opacity:1;fill:url(#linearGradient3064)"
                   begin="light_1.end"
                   dur="1s"
                   values="0;1"
                   attributeName="fill-opacity"
                   id="light_2" />           </text>
                      <text
                         xml:space="preserve"
                         id="text18604"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18606);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18610"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18612);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18616"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18618);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18622"
                         style="font-style:normal;font-weight:normal;font-size:10.5833px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18624);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <text
                         xml:space="preserve"
                         id="text18628"
                         style="font-style:normal;font-weight:normal;font-size:12.7px;line-height:125%;font-family:sans-serif;text-align:justify;letter-spacing:0px;word-spacing:0px;white-space:pre;shape-inside:url(#rect18630);fill:url(#linearGradient2950);fill-opacity:1;stroke:none;stroke-width:1.78339px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="0s;light_2.end"
                         dur="1s"
                         values="1;0"
                         attributeName="fill-opacity"
                         id="light_1" />
                      <animate
                         style="fill-opacity:1;fill:url(#linearGradient2950)"
                         begin="light_1.end"
                         dur="1s"
                         values="0;1"
                         attributeName="fill-opacity"
                         id="light_2" />
                    </g>
                    <rect
                       ry="7.1295042"
                       rx="10.726021"
                       y="-2.8428149"
                       x="-4.4855061"
                       height="16.413473"
                       width="25.987757"
                       id="rect871"
                       style="opacity:0;fill:#c6126a;stroke:#babd06;stroke-width:0.0794996;stroke-opacity:0.00424254" />
                  </g>
                  <style
                     id="style43">
                           #tspan18600 {
                               
                              animation-name: mecOpacity;
                              animation-duration: 2s;
                              animation-iteration-count: infinite;
                              }
                              @keyframes mecOpacity {
                              0%   { fill-opacity:1 }
                                50%  {fill-opacity :0.1; }
                            100% { fill-opacity: 1; }
                              }
                    </style>
                </svg>
                </a>
            <a href="#" data-activates="mobile-demo" class="button-collapse"><i class="material-icons">menu</i></a>

            <ul class="right hide-on-med-and-down">
                <!--  <li> <a class="btn" onclick="Materialize.toast('Hello', 4000, 'Ciao' ,4000 )">Touch Me</a> </li>
              -->

              <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
              <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
                <li>
                    <a href=""> </a>
                </li>
                <li>
                    <a href=""> </a>
                </li>
            </ul>
          
              <ul class="side-nav" id="mobile-demo">
               <li><a href="http://www.mecbar.com/#Ablog">Blog</a></li>
              <li><a href="http://www.mecbar.com/#Ablock">Blockchain</a></li>
                 <li><a href="http://www.mecbar.com/#quantum">Quantum</a></li>
              <li><a href="http://www.mecbar.com/#Amachine">Machine Learning</a></li>
              <li><a href="http://www.mecbar.com/#Alinux">Linux</a></li>
              <li><a href="http://www.mecbar.com/#Aus">Contatti</a></li>
            </ul>
        
            </li>
    </nav>
</header>
<script>
    MathJax = {
      loader: {load: ['input/asciimath', 'output/chtml']}
    }
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<div class="center titolo">
    <i>Sequence To Sequence Translation with PyTorch </i>
 </div>
 <div class="testo">
Utilizzando un modello RNN come encoder ed un altro modello RNN come decoder si crea un 
modello di translation come ad esempio la translation da una lingua ad un'altra inserendo una sequenza di parole 
in una lingua in input ed ottenere in output una sequenza nell'altra lingua. <br>
Questo modello può essere utilizzato anche per altri scopi come ad esempio un modello per Domande-Risposte 
per creare un ChatBot o text transcript o text summarization.<br>

Qui prendiamo anche in considerazione anche l'Attention mechanism un nuovo modello che consiste 
nel prendere oltre ai context vector i weights creati nell'encoder e li somma con quelli creati dall'attention per poi passarli 
in input al decoder per avere un risultato migliore. <br><br>
<img src="foto/rnn_encoder.png" width="40%" height="190px"><img src="foto/rnn_decoder.png" width="60%" height="190px">

<br><br>

Vediamo come in questo esempio si procede dopo aver creato un file di testo che contenga parallelamente 
delle frasi con le 2 lingue. <br>
Con la class CreaInputFile per ogni record del file testo come il seguente :<br>
[‘Ciao’, ‘Hello’]  si procede alla Normalizzazione(eliminazione punteggiatura) 
e si ottiene in output un Tensor che con la utility di Torch creiamo il dataLoader <br><br>
Vediamo il risultato di CreaInputFile ossia i vocabolari ed il pairs.<br><br>


inputFile.inputLingua.index2word

<div class="model2">
{0: 'SOS',<br>
 1: 'EOS',<br>
 2: 'io',<br>
 3: 'non',<br>
 4: 'ho',<br>
 5: 'fretta',<br>
 ....}<br>
</div>
 

 inputFile.inputLingua.word2count

 <div class="model2">
 {'io': 948,<br>
 'non': 819,<br>
 'ho': 91,<br>
 'fretta': 6,<br>
 '.': 4959,<br>
 'sta': 114,<br>
 'facendo': 40,<br>
 .... }<br>
 </div>

 inputFile.inputLingua.word2index
 
 <div class="model2">
 { 'invitato': 945,<br>
 'cugine': 946,<br>
 'cattiva': 947,<br>
 'influenza': 948,<br>
 'preziosa': 949,<br>
 'fallira': 950,<br>
 'interferendo': 951,<br>
 'insegnando': 952,<br>
 'pericolosa': 953,<br>
 'zucchero': 954,<br>
 .... }<br>
 </div>
 
e così anche in output ... <br>
inputFile.outputLingua.index2word
<div class="model2">
{.... <br>
 935: 'also',<br>
 936: 'live',<br>
 937: 'exaggerating',<br>
 938: 'swimming',<br>
 939: 'fast',<br>
 .... }<br>
</div>


 inputFile.outputLingua.word2count
 <div class="model2">
{ .....<br>
 'eighteen': 3,<br>
 'baffled': 1,<br>
 'discussing': 1,<br>
 'cynical': 1,<br>
 'following': 4,<br>
..... }<br>
 </div>

inputFile.outputLingua.word2index

<div class="model2">
{ .....<br>
'eighteen': 946,<br>
 'baffled': 947,<br>
 'discussing': 948,<br>
 'cynical': 949,<br>
 'following': 950,<br>
 'courageous': 951,<br>
 ..... }<br>
</div>


 inputFile.pairs
 <div class="model2">
{ .....<br>
 ['sto soltanto ascoltando .', 'i m just listening .'],<br>
 ['non sono la .', 'they re not there .'],<br>
 ['siamo prive di ambizione .', 'we re unambitious .'],<br>
 ['tu hai diritto alla tua opinione .', 'you are entitled to your opinion .'],<br>
 ['e bello .', 'you re beautiful .'],<br>
 ['sono tutti turisti .', 'they re all tourists .'],<br>
 <br>
 ..... }
 </div>

 inputFile.tensor
 <div class="model2">
 [....<br>
 (tensor([[ <br>
 <span style="margin-left:60px"> 21],</span><br>
 <span style="margin-left:60px">   [  16],</span><br>
   <span style="margin-left:60px">  [ 200],</span><br>
   <span style="margin-left:60px">  [ 341],</span><br>
  <span style="margin-left:60px">  [1104],</span><br>
 <span style="margin-left:60px">   [ 205],</span><br>
  <span style="margin-left:60px">  [   1]]), tensor([[ 17],</span><br>
  <span style="margin-left:60px">    [107],</span><br>
   <span style="margin-left:60px">  [293],</span><br>
  <span style="margin-left:60px"> [ 26],</span><br>
  <span style="margin-left:60px"> [403],</span><br>
 <span style="margin-left:60px"> [404],</span><br>
 <span style="margin-left:60px">  [  1]]))</span><br>
.... ]<br>

</div>

Dopo aver creato il dataLoader passiamo a definire l'Optimizer Function per l'Encoder ed il Decoder  
poi si definisce la Loss Function. <br>
Con la Train Function si creano i modelli per L'EncoderRNN e per l'AttentionDecoderRNN. <br>
Poi con la function test effettueremo una valutazione dei modelli creati inserendo una frase in italiano 
ottenendo in output la traduzione in inglese.  
<br><br>
<div class="model3">
from __future__ import unicode_literals, print_function, division<br>

import random<br>
import re<br>
import unicodedata<br>
from io import open<br>
import torch<br>
import torch.nn as nn<br>
import pandas as pd<br>
import matplotlib.pyplot as plt<br>
import matplotlib.ticker as ticker<br>
</div>

<br><br>
<div class="model3">
data = pd.read_csv(filename, sep='\t')<br>
eng = data.iloc[:,0]<br>
ita = data.iloc[:,1]<br>
df = pd.DataFrame({0:ita,1:eng})<br>
with open('ita-eng.txt', 'w') as f:<br>
<span style="margin-left:30px"> f.write(</span><br>
    <span style="margin-left:60px"> df.to_csv(header = False, index = False)</span><br>
        <span style="margin-left:60px"> )</span><br>
    <br><br>
SOS = 0   # start of string<br>
EOS = 1   # end of string <br>
    
LUNG_MAX = 10 <br>   
DATASETSIZE = len(data)    # numero pairs lingua1 - lingua2<br>
HIDDEN_SIZE = 256<br>
</div>
<div class="model3">
<span class="nero"> class</span> Lingua: <br>
<span style="margin-left:30px"> """Class per creare il vocabolario per ogni lingua 
    creazione word2index - indextoword - word2count e numero parole """</span><br>
<br> 
 <span style="margin-left:30px"><span class="nero"> def</span>  __init__(self, lingua):</span><br>
  <span style="margin-left:60px"> self.lingua = lingua</span><br>
  <span style="margin-left:60px">self.word2index = {}</span><br>
  <span style="margin-left:60px">self.word2count = {}</span><br>
  <span style="margin-left:60px">self.index2word = {0: "SOS", 1: "EOS"}</span><br>
  <span style="margin-left:60px">self.numeroParole = 2  # si parte da 2 (SOS e EOS)</span><br>
  <br>
 <span style="margin-left:30px"> <span class="nero"> def </span> addSentence(self, sentence):</span><br>
 <span style="margin-left:60px">for word in sentence.lower().split(' '):</span><br>
    <span style="margin-left:90px">if word not in self.word2index:</span><br>
   <span style="margin-left:120px">self.word2index[word] = self.numeroParole</span><br>
  <span style="margin-left:120px">self.word2count[word] = 1</span><br>
 <span style="margin-left:120px">self.index2word[self.numeroParole] = word</span><br>
  <span style="margin-left:120px">self.numeroParole += 1</span><br>
   <span style="margin-left:90px">else:</span><br>
 <span style="margin-left:120px">self.word2count[word] += 1</span><br>
    
</div>
<div class="model3">
 <span class="nero">
class </span> creaInputFile(torch.utils.data.Dataset):<br>
<span style="margin-left:30px">""" crea Dataset per modello Encoder-Decoder Translator  </span><br>
 <span style="margin-left:30px">crea vocabolario con numtoparola e parolatonumero</span><br>
 <span style="margin-left:30px">input language e output language vengono convertite in TENSOR  """</span><br>
 <br>
<span style="margin-left:30px"><span class="nero"> def </span> __init__(self, inputFile, datasetSize: int, reverse= False):</span><br>
 <span style="margin-left:60px">""" reverse = True se si vuole invertire la traduzione """</span><br>
 <span style="margin-left:60px">lines = open(inputFile, encoding='utf-8').read().strip().split('\n')</span><br>

   <span style="margin-left:60px"># Split lines in coppie nelle 2 lingue pairs e togliere caratteri non lettere </span><br>
 <span style="margin-left:60px">pairs = [[self.normalizzazione(stringa.strip() ) for stringa in l.split(',')] for l in lines]</span><br>
      
 <span style="margin-left:60px">if reverse:</span><br>
 <span style="margin-left:90px">pairs = [list(reversed(pair)) for pair in pairs]</span><br>
        
    
  <span style="margin-left:60px">self.inputLingua = Lingua('ita')</span><br>
 <span style="margin-left:60px">self.outputLingua = Lingua('eng')</span><br>

   <span style="margin-left:60px"> # Filter the pairs to reduce the size of the dataset</span><br>
 <span style="margin-left:60px">filtro = list()</span><br>
  <span style="margin-left:60px">english = (</span><br>
 <span style="margin-left:90px"> "i am ", "i m ",</span><br>
 <span style="margin-left:90px"> "he is", "he s ",</span><br>
 <span style="margin-left:90px"> "she is", "she s ",</span><br>
 <span style="margin-left:90px"> "you are", "you re ",</span><br>
 <span style="margin-left:90px"> "we are", "we re ",</span><br>
 <span style="margin-left:90px"> "they are", "they re "</span><br>
<span style="margin-left:90px">  )</span><br>
        
        
 <span style="margin-left:60px"> for pair in pairs:</span><br>

 <span style="margin-left:90px"> if len(pair[0].split(' ')) < LUNG_MAX and \</span><br>
 <span style="margin-left:120px"> len(pair[1].split(' ')) < LUNG_MAX and \</span><br>
 <span style="margin-left:120px">  pair[1].startswith(english):</span><br>
   <span style="margin-left:90px"> filtro.append(pair)</span><br>
  <span style="margin-left:60px"> pairs = filtro</span><br>
 <span style="margin-left:60px"> pairs = [random.choice(pairs) for _ in range(datasetSize)]</span><br>

 <span style="margin-left:60px"> # Crea vocabolario</span><br>
 <span style="margin-left:60px"> for pair in pairs:</span><br>
 <span style="margin-left:90px"> self.inputLingua.addSentence(pair[0])</span><br>
 <span style="margin-left:90px"> self.outputLingua.addSentence(pair[1])</span><br>

 <span style="margin-left:60px"> self.pairs = pairs</span><br>
 <span style="margin-left:60px"> self.tensor = []</span><br>

 <span style="margin-left:60px"> # Converte le frasi in tensor inserendo EOS al termine frase</span><br>
<span style="margin-left:60px"> for pair in self.pairs:</span><br>
 <span style="margin-left:90px"> inputSentence = \</span><br>
 <span style="margin-left:120px"> [self.inputLingua.word2index[word] for word in pair[0].split(' ')] + [EOS]</span><br>

 <span style="margin-left:90px">  outputSentence = \</span><br>
  <span style="margin-left:120px"> [self.outputLingua.word2index[word] for word in pair[1].split(' ')] + [EOS]</span><br>

  <span style="margin-left:90px"> inputSentenceTensor = torch.tensor(inputSentence, dtype=torch.long).view(-1, 1)</span><br>
 <span style="margin-left:90px"> outputSentenceTensor = torch.tensor(outputSentence, dtype=torch.long).view(-1, 1)</span><br>

 <span style="margin-left:90px">  self.tensor.append((inputSentenceTensor, outputSentenceTensor))</span><br>
 <br>
<span style="margin-left:30px"> <span class="nero">def</span>  normalizzazione(self, stringa):</span><br>
 <span style="margin-left:60px">stringa = ''.join(</span><br>
<span style="margin-left:90px"> c for c in unicodedata.normalize('NFD', stringa.lower().strip())</span><br>
 <span style="margin-left:90px"> if unicodedata.category(c) != 'Mn'</span><br>
  <span style="margin-left:90px">)</span><br>
 <span style="margin-left:60px">stringa = re.sub(r"([.!?])", r" \1", stringa)</span><br>
  <span style="margin-left:60px">stringa = re.sub(r"[^a-zA-Z.!?]+", r" ", stringa)</span><br>
 <span style="margin-left:60px">return stringa</span><br>
 <br>
<span style="margin-left:30px"> <span class="nero">def </span> seqTOseq(self, frase: str):</span><br>
  <span style="margin-left:60px">"""inserisco frase in un tensor"""</span><br>
 <span style="margin-left:60px">seq = [self.inputLingua.word2index[word] for word in self.normalizzazione(frase).split(' ')] + [EOS]</span><br>
  <span style="margin-left:60px">seq = torch.tensor(seq, dtype=torch.long).view(-1, 1)</span><br>
  <span style="margin-left:60px"> return seq</span><br><br>
  <span style="margin-left:30px"> <span class="nero">def </span> __len__(self): </span><br>
  <span style="margin-left:60px"> return len(self.tensor)</span><br>
  <br>
 <span style="margin-left:30px"> <span class="nero">  def </span> __getitem__(self, idx):</span><br>
 <span style="margin-left:60px"> return self.tensor[idx]</span><br>
</div> 

<div class="model3">
  <span  class="nero"> class </span> EncoderRNN(nn.Module):<br>
 <span style="margin-left:30px">  <span  class="nero">def </span> __init__(self, input_size, hidden_size):</span><br>
 <span style="margin-left:60px">super(EncoderRNN, self).__init__()</span><br>
   <span style="margin-left:60px">self.input_size = input_size</span><br>
 <span style="margin-left:60px">self.hiddenSize = hidden_size</span><br>
   <span style="margin-left:60px"> # Embedding for the input words</span><br>
  <span style="margin-left:60px">self.embedding = torch.nn.Embedding(input_size, hidden_size)</span><br>
  <span style="margin-left:60px"># rnn con GRU o LSTM </span><br>
 <span style="margin-left:60px">self.rnn = torch.nn.GRU(hidden_size, hidden_size)</span><br>
 <br><br>
 <span style="margin-left:30px">  <span  class="nero">def </span>forward(self, input, hidden):</span><br>
 
    <span style="margin-left:60px"> embedded = self.embedding(input).view(1, 1, -1)</span><br>
  <span style="margin-left:60px"> output, hidden = self.rnn(embedded, hidden)</span><br>
   <span style="margin-left:60px"> return output, hidden</span><br>
   <br><br>
 <span style="margin-left:30px"> <span  class="nero"> def </span> hidden(self):</span><br>
 <span style="margin-left:60px"> return torch.zeros(1, 1, self.hiddenSize)</span><br>
</div>

<div class="model3">

 <span  class="nero">class </span>AttentionDecoderRNN(nn.Module):<br>
 <span style="margin-left:30px"> <span  class="nero"> def </span> __init__(self, hidden_size, output_size, maxL=LUNG_MAX,</span><br>
 <span style="margin-left:60px">dropout=0.2):</span><br>
 <span style="margin-left:60px">super(AttentionDecoderRNN, self).__init__()</span><br>
  <span style="margin-left:60px">self.hiddeSize = hidden_size</span><br>
 <span style="margin-left:60px">self.outputSize = output_size</span><br>
 <span style="margin-left:60px"> self.maxL = maxL</span><br>
        
 <span style="margin-left:60px"># Embedding for the input word</span><br>
  <span style="margin-left:60px">self.embedding = torch.nn.Embedding(self.outputSize, self.hiddeSize)</span><br>
<span style="margin-left:60px">self.dropout = torch.nn.Dropout(dropout)</span><br>
<span style="margin-left:60px"># Attention portion</span><br>
  <span style="margin-left:60px">self.attn = torch.nn.Linear(in_features=self.hiddeSize, out_features=self.hiddeSize)</span><br>
 <span style="margin-left:60px">self.w_c = torch.nn.Linear(in_features=self.hiddeSize * 2, out_features=self.hiddeSize)</span><br>
<span style="margin-left:60px"># RNN  GRU o LSTM</span><br>
 <span style="margin-left:60px">self.rnn = torch.nn.GRU(input_size=self.hiddeSize, hidden_size=self.hiddeSize)</span><br>
  <span style="margin-left:60px"> # Output word</span><br>
  <span style="margin-left:60px">self.w_y = torch.nn.Linear(in_features=self.hiddeSize, out_features=self.outputSize)</span><br>
  <br>
<span style="margin-left:30px">  <span  class="nero">  def </span> forward(self, input, hidden, E_outputs):</span><br>
 <span style="margin-left:60px"> embedded = self.embedding(input).view(1, 1, -1)</span><br>
 <span style="margin-left:60px">embedded = self.dropout(embedded)</span><br>
        
 <span style="margin-left:60px">rnn_out, hidden = self.rnn(embedded, hidden)</span><br>
<span style="margin-left:60px">scores = torch.mm(self.attn(hidden)[0], E_outputs.t())</span><br>
 <span style="margin-left:60px"> attentionWeights = torch.nn.functional.softmax(scores, dim=1)</span><br>
 <span style="margin-left:60px"> c_t = torch.mm(attentionWeights, E_outputs)</span><br>
 <span style="margin-left:60px">hidden_s_t = torch.cat([hidden[0], c_t], dim=1)</span><br>
 <span style="margin-left:60px">hidden_s_t = torch.tanh(self.w_c(hidden_s_t))</span><br>
 <span style="margin-left:60px">output = torch.nn.functional.log_softmax(self.w_y(hidden_s_t), dim=1)</span><br>
        
 <span style="margin-left:60px">return output, hidden, attentionWeights</span><br>
    
</div>
<div class="model3">
 <span  class="nero">def </span> train(encoder, decoder, lossF, E_optimizer, D_optimizer, dataLoader, maxL=LUNG_MAX):<br>
<span style="margin-left:30px"> total_loss = 0</span><br>
 <span style="margin-left:30px"> # Iterate over dataLoader</span><br>
 <span style="margin-left:30px"> for i, (X, y) in enumerate(dataLoader):</span><br>
   <span style="margin-left:60px"> X = X.squeeze(0)</span><br>
  <span style="margin-left:60px"> y = y.squeeze(0)</span><br>
   <span style="margin-left:60px"> E_hidden = encoder.hidden()</span><br>
  <span style="margin-left:60px"> E_optimizer.zero_grad()</span><br>
  <span style="margin-left:60px"> D_optimizer.zero_grad()</span><br>
  <span style="margin-left:60px"> X_length = X.size(0)</span><br>
  <span style="margin-left:60px"> y_length= y.size(0)</span><br>
   <span style="margin-left:60px"> EZ_output= torch.zeros(maxL, encoder.hidden_size)</span><br>
  <span style="margin-left:60px"> loss = torch.Tensor([0]).squeeze()</span><br>
 <span style="margin-left:60px">  with torch.set_grad_enabled(True):</span><br>
 <span style="margin-left:90px"> # inserite sequence in encoder hidden states </span><br>
 <span style="margin-left:90px">for inp in range(X_length):</span><br>
<span style="margin-left:120px">E_output, E_hidden = encoder( X[inp], E_hidden)</span><br>
 <span style="margin-left:120px">EZ_output[inp] = E_output[0, 0]</span><br>
 <span style="margin-left:90px"># decoder inizializzato con SOS</span><br>
<span style="margin-left:90px">decoder_input = torch.tensor([[SOS]])</span><br>
 <span style="margin-left:90px"># istanziare decoder con dati ultimo encoder hidden state</span><br>
 <span style="margin-left:90px">decoder_hidden = E_hidden</span><br>

 <span style="margin-left:90px"># inserimento target come prossimo input</span><br>
 <span style="margin-left:90px">for tar in range(y_length):</span><br>
 <span style="margin-left:120px">decoder_output, decoder_hidden, decoder_attention = decoder(</span><br>
 <span style="margin-left:120px">decoder_input, decoder_hidden, EZ_output)</span><br>
 <span style="margin-left:120px">loss += lossF(decoder_output, y[tar])</span><br>
 <span style="margin-left:120px">decoder_input = y[tar] </span><br>

<span style="margin-left:90px">loss.backward()  # back-propagation</span><br>
<span style="margin-left:90px">E_optimizer.step()</span><br>
 <span style="margin-left:90px">D_optimizer.step() </span><br> 
            
<span style="margin-left:60px">total_loss += loss.item() / y_length</span><br>

  <span style="margin-left:60px">iterator = i + 1</span><br>
 <span style="margin-left:60px">if iterator % 1000 == 0:</span><br>
 <span style="margin-left:90px">lossA = total_loss / 1000</span><br>
 <span style="margin-left:90px">total_loss = 0</span><br>
 <span style="margin-left:90px">print(f'Iterazioni:  {iterator } { 100*iterator/len(dataLoader) :.2f} %   Loss: { lossA :.5f}')
</span><br>
</div>
<div class="model3">
<span  class="nero">def </span> test(encoder, decoder, frase, maxL=LUNG_MAX):<br>
<span style="margin-left:30px">tensorI = inputFile.seqTOseq(frase)</span><br>
<span style="margin-left:30px">with torch.no_grad():</span><br>
<span style="margin-left:60px">X_length = tensorI.size()[0]</span><br>
<span style="margin-left:60px">E_hidden = encoder.hidden()</span><br>
        
<span style="margin-left:60px">EZ_output= torch.zeros(maxL, encoder.hidden_size)</span><br>
        
<span style="margin-left:60px">for inp in range(X_length):</span><br>
<span style="margin-left:90px"># Pass frase nel encoder </span><br>
<span style="margin-left:90px">E_output, E_hidden = encoder(tensorI[inp], E_hidden)</span><br>
<span style="margin-left:90px"> EZ_output[inp] += E_output[0, 0]</span><br>
        
  <span style="margin-left:60px"># decoder init con ultimo encoder hidden state</span><br>
<span style="margin-left:60px">decoder_input = torch.tensor([[SOS]])  # GO</span><br>
        
<span style="margin-left:60px"># Initiate decoder con ultimo encoder hidden state</span><br>
<span style="margin-left:60px">decoder_hidden = E_hidden</span><br>
        
<span style="margin-left:60px">decoded_words = []</span><br>
<span style="margin-left:60px">decoder_attentions = torch.zeros(maxL, maxL)</span><br>
        
<span style="margin-left:60px">for tar in range(maxL):</span><br>
<span style="margin-left:90px">decoder_output, decoder_hidden, decoder_attention = decoder(</span><br>
<span style="margin-left:120px">decoder_input, decoder_hidden, EZ_output)</span><br>
<span style="margin-left:90px">decoder_attentions[tar] = decoder_attention.data</span><br>
        
<span style="margin-left:90px"># output word index con >  probability</span><br>
<span style="margin-left:90px">_, topK = decoder_output.data.topk(1)</span><br>
<span style="margin-left:90px">if topK.item() != EOS:</span><br>
<span style="margin-left:120px"> decoded_words.append(inputFile.outputLingua.index2word[topK.item()])</span><br>
<span style="margin-left:90px">else:</span><br>
<span style="margin-left:120px">break</span><br>
        
<span style="margin-left:90px"> # ultima output word è la prima in input</span><br>
<span style="margin-left:90px">decoder_input = topK.squeeze().detach()</span><br>
        
<span style="margin-left:60px">return decoded_words, decoder_attentions[:tar + 1]</span><br>
</div>    
<div class="model3">
<span  class="nero">          
def </span> plotAttentions(input, output, attentions):<br>
<span style="margin-left:30px"># Setup figure</span><br>
 <span style="margin-left:30px">fig = plt.figure()</span><br>
 <span style="margin-left:30px">ax = fig.add_subplot(111)</span><br>
<span style="margin-left:30px">cax = ax.matshow(attentions.numpy(), cmap='bone')</span><br>
<span style="margin-left:30px">fig.colorbar(cax)</span><br>
                
 <span style="margin-left:30px"># Setup axes</span><br>
   <span style="margin-left:30px">ax.set_xticklabels([''] + input.split(' ') +</span><br>
 <span style="margin-left:90px"> ['<EOS>'], rotation=90)</span><br>
<span style="margin-left:30px">ax.set_yticklabels([''] + output)</span><br>
                
<span style="margin-left:30px"># Show label</span><br>
 <span style="margin-left:30px">ax.xaxis.set_major_locator(ticker.MultipleLocator(1))</span><br>
 <span style="margin-left:30px"> ax.yaxis.set_major_locator(ticker.MultipleLocator(1))</span><br>
                
<span style="margin-left:30px">plt.show()</span><br>
                
</div>

<div class="model3">
<span  class="nero">def </span> Test(frase, encoder, decoder):<br>
<span style="margin-left:30px">input = inputFile.seqTOseq(frase)</span><br>
                
  <span style="margin-left:30px"> output, attentions = test(encoder=encoder,</span><br>
  <span style="margin-left:90px"> decoder=decoder,</span><br>
  <span style="margin-left:90px"> frase=frase)</span><br>
                
  <span style="margin-left:30px">plotAttentions(frase, output, attentions)</span><br>
                
</div>          

<div class="model3">
# creazione tensor da pairs 2 lingue per passare input al modello  <br>
inputFile = creaInputFile('ita-eng.txt', DATASETSIZE)<br>
<br><br>
# creazione DataLoader - blocchi di record con utility di Torch contiene x e y<br>
dataLoader = torch.utils.data.DataLoader(inputFile,batch_size=1, shuffle=False)<br>
<br><br>

# istanza dei modelli RNN per Encoder e Decoder<br>
encoderRNN = EncoderRNN(inputFile.inputLingua.numeroParole, HIDDEN_SIZE)<br>
decoderRNN = AttentionDecoderRNN(HIDDEN_SIZE, inputFile.outputLingua.numeroParole, dropout=0.1)<br>
<br><br>

# definizione optimizer per enconder e decoder con parametri dei modelli<br>
optimizerFORencoder = torch.optim.Adam(encoderRNN.parameters())<br>
optimizerFORdecoder = torch.optim.Adam(decoderRNN.parameters())<br>
# loss = torch.nn.NLLLoss()<br>
loss = torch.nn.CrossEntropyLoss()<br>
<br><br>
train(encoderRNN , decoderRNN , loss, optimizerFORencoder , optimizerFORdecoder, dataLoader)<br>
<br><br>

traduzione, attentions = test(encoderRNN , decoderRNN, "sono molto felice")<br>
plt.matshow(attentions.numpy())<br>
print(traduzione)<br><br>
['i', 'm', 'very', 'happy']<br><br>

<img src="foto/attention.png" width="40%" height="190px">
<br><br>



<br><br>

Traduzione = Test("io sono tuo amico", encoderRNN, decoderRNN)<br><br>

print(Traduzione)<br><br>

i m your friends <br><br><br><br>
<img src="foto/trasl1.png" width="80%" height="350px">
<br><br>



</div>




 </div>










</html>